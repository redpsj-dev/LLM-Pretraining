{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redpsj-dev/LLM-Pretraining/blob/main/01_pretraining_ko.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UldY1o4dz4z"
      },
      "source": [
        "___\n",
        "<a href='https://honglab.ai'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
        "___\n",
        "<center><em>Content Copyright by HongLab, Inc.</em></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1IYcc4Hdz41"
      },
      "source": [
        "## 대형언어모델(LLM) 바닥부터 만들기\n",
        "\n",
        "[유튜브 강의 영상 링크](https://youtu.be/osv2csoHVAo)\n",
        "\n",
        "[홍정모 연구소 디스코드 링크](https://discord.com/invite/kgR9xJkbsV)\n",
        "\n",
        "[홍정모 연구소 홈페이지 링크](https://www.honglab.ai/)\n",
        "\n",
        "#### 참고 자료\n",
        "- [Andrej Karpathy 유튜브](https://www.youtube.com/andrejkarpathy)\n",
        "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
        "- [Om-Alve/smolGPT 깃헙](https://github.com/Om-Alve/smolGPT)\n",
        "- 트랜스포머 논문 - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "- OpenAI GPT2 논문 - [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAzoBJc9dz41"
      },
      "source": [
        "#### 안내사항\n",
        "\n",
        "LLM의 핵심 개념을 개인 PC에서도 간단하게 실습하면서 공부할 수 있는 학습 자료입니다. 널리 알려진 교육/학술 자료들을 참고하여 쉽게 공부할 수 있도록 요약하고 정리한 것입니다. 코딩 스타일이나 활용 범위에 대해 오해 없으시길 바랍니다.\n",
        "\n",
        "윈도우11/WSL, Python 3.9.20, Pytorch 2.6, CUDA 12.6 에서 작동을 확인하였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2YODi3qdz42"
      },
      "source": [
        "#### 전체 과정 요약\n",
        "\n",
        "LLM 기반 AI 에이전트를 만들때는 핵심이 되는 LLM이 필요한데요, LLM을 바닥부터 만드는 경우 보다는 공개되어 있는 LLM 모델들을 가져다가 나의 용도에 맞도록 다듬어서 사용하는 것이 일반적입니다. 다만, 최근에는 LLM을 바닥부터 만드는 기술에 대한 진입장벽이 낮아지고 있어서 회사별로 필요한 LLM을 바닥부터 각자 만들어 사용하게 될 가능성도 높아지고 있습니다.\n",
        "\n",
        "LLM을 만들 때는\n",
        "\n",
        "1. 사전훈련(pretraining)으로 일반적인 언어 능력을 가르친 후에\n",
        "2. 미세조정(fine tuning) 단계에서 특정 업무에 적응\n",
        "\n",
        "시키는 것이 기본이 됩니다. 여기에\n",
        "\n",
        "3. 데이터베이스(+인터넷) 검색 기능을 추가\n",
        "\n",
        "하면 지식의 범위와 정확성을 높일 수 있습니다. 사람이 생각을 거듭하여 더 깊이있는 결론을 이끌어 내듯이 LLM도\n",
        "\n",
        "4. 내부적으로 질의를 반복하여 더 좋은 결론을 도출\n",
        "\n",
        "하도록 만들 수 있습니다.\n",
        "\n",
        "여기서는 LLM의 기본 원리를 이해하기 위해서 사전훈련 과정을 바닥부터 진행해보겠습니다. 훈련 과정의 큰 틀은 일반적인 머신러닝 절차를 따릅니다.\n",
        "\n",
        "1. 훈련 데이터 준비\n",
        "1. 데이터 로더 정의\n",
        "1. 모델 정의\n",
        "1. 훈련\n",
        "1. 결과 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxCBqfOQdz42"
      },
      "source": [
        "#### 훈련 데이터 준비\n",
        "\n",
        "준비한 텍스트 파일을 읽어 들여서 정리한 후에 앞에 cleaned_가 붙은 파일 이름으로 정리합니다.\n",
        "> 예시) alice.txt &rarr; cleaned_alice.txt\n",
        "\n",
        "- 캐글 해리포터 책 - [Harry Potter Books](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
        "- 캐글 앨리스 책 - [alice.txt](https://www.kaggle.com/datasets/leelatte/alicetxt)\n",
        "- 훈련 데이터나 가중치는 제가 배포하지 않습니다. 직접 다운받거나 준비하셔야합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yrjFhYfOdz42",
        "outputId": "5e52f50c-3c53-46dd-9d74-d9a849131a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cleaned_ko_novel.txt 1138003 characters\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        book_text = file.read()\n",
        "\n",
        "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # 줄바꿈을 빈칸으로 변경\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러 빈칸을 하나의 빈칸으로\n",
        "\n",
        "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # 글자 수 출력\n",
        "\n",
        "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "filenames_list = [\"ko_novel.txt\"]\n",
        "\n",
        "for filename in filenames_list:\n",
        "    clean_text(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmr88oW3dz43"
      },
      "source": [
        "#### 토큰화\n",
        "\n",
        "UTF-8 BPE(Bype Pair Encoding)\n",
        "- GPT-2\n",
        "  - 서브워드 토크나이징: 자주 등장하지 않는 단어는 더 작은 단위로 쪼개짐\n",
        "  - 효율성: 자주 등장하는 단어나 구는 하나의 토큰으로 표현됨\n",
        "  - 다국어 처리: 영어가 아닌 언어는 토큰화가 덜 효율적일 수 있음\n",
        "\n",
        "- 토큰화 된 숫자들은 GPT-2 토크나이저의 어휘 사전(vocabulary)에서 각 토큰에 할당된 고유 ID임.\n",
        "- 예를 들어, \"Harry\"는 18308번, \"Potter\"는 14179번 같은 식으로 매핑되어 있음."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6oj7IBvaeJcq",
        "outputId": "fcb378ea-c8b8-49d6-e83c-d32e57d680ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.23.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m854.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install ipywidgets\n",
        "!pip install tiktoken\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rtJGh9r1dz44",
        "outputId": "08333c3f-7f36-457d-f40e-6ddcc52eb7fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "글자수: 220 토큰수 52\n",
            "[13059, 353, 318, 262, 33630, 1295, 284, 7808, 340, 13, 447, 251, 5850, 2067, 284, 1560, 606, 546, 18373, 11, 475, 19959, 19072, 13, 564, 250, 1135, 1541, 760, 851, 356, 2982, 8129, 11130, 261, 44906, 5149, 8129, 1610, 270, 16239, 428, 3329, 13, 1320, 447, 247, 82, 1521, 356, 3066, 356]\n",
            "potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we\n",
            "13059\t -> pot\n",
            "353\t -> ter\n",
            "318\t ->  is\n",
            "262\t ->  the\n",
            "33630\t ->  safest\n",
            "1295\t ->  place\n",
            "284\t ->  to\n",
            "7808\t ->  hide\n",
            "340\t ->  it\n",
            "13\t -> .\n",
            "447\t -> �\n",
            "251\t -> �\n",
            "5850\t ->  Harry\n",
            "2067\t ->  started\n",
            "284\t ->  to\n",
            "1560\t ->  tell\n",
            "606\t ->  them\n",
            "546\t ->  about\n",
            "18373\t ->  Colin\n",
            "11\t -> ,\n",
            "475\t ->  but\n",
            "19959\t ->  Hermione\n",
            "19072\t ->  interrupted\n",
            "13\t -> .\n",
            "564\t ->  �\n",
            "250\t -> �\n",
            "1135\t -> We\n",
            "1541\t ->  already\n",
            "760\t ->  know\n",
            "851\t ->  —\n",
            "356\t ->  we\n",
            "2982\t ->  heard\n",
            "8129\t ->  Professor\n",
            "11130\t ->  McG\n",
            "261\t -> on\n",
            "44906\t -> agall\n",
            "5149\t ->  telling\n",
            "8129\t ->  Professor\n",
            "1610\t ->  Fl\n",
            "270\t -> it\n",
            "16239\t -> wick\n",
            "428\t ->  this\n",
            "3329\t ->  morning\n",
            "13\t -> .\n",
            "1320\t ->  That\n",
            "447\t -> �\n",
            "247\t -> �\n",
            "82\t -> s\n",
            "1521\t ->  why\n",
            "356\t ->  we\n",
            "3066\t ->  decided\n",
            "356\t ->  we\n"
          ]
        }
      ],
      "source": [
        "import tiktoken # pip install tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "text = \"potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we\"\n",
        "\n",
        "tokens = tokenizer.encode(text)\n",
        "\n",
        "print(\"글자수:\", len(text), \"토큰수\", len(tokens))\n",
        "print(tokens)\n",
        "print(tokenizer.decode(tokens))\n",
        "for t in tokens:\n",
        "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "cdbf843241ef435ab85260cce138eae7",
            "fbfe6d064d3c49d8940a868a2201d2af",
            "77d6e40c1d194839aab5b35a1687724c",
            "e81b43d7d8a745a18a7563179ec28f45",
            "e6c4c1f68a6b4998aecc3c26d8896c31",
            "2a404dc52f6b408baf80d8af8dcbed48",
            "0e00ac2dfc524c3783fe260fbcb31198",
            "9626c19cb38947c98783c8e6b998cca4",
            "ac3e27c16a3941e4be71aafc6ff403c7",
            "c4a8c516b548407798b2cfc70427e933",
            "2ef88adb1af046a98712f191eb95bf31",
            "9671b4f3db824a1fa0fb501510e554b9",
            "7bcedac520654505bd3799eac5cc5d6c",
            "db8c987f8c924ac79e62c953b64b81b1",
            "13e0a01171964a3daa73f5ca10c8d4cd",
            "318d3ccc42084c85819455a8f11941be",
            "4bd0aec2fa3241ccbd8e255ae1e92754",
            "84002fcbbd2b45be894f82c8566c1228",
            "783930df6c7e4a47b4608712ce3f0c1e",
            "e85eca346b234baa8546c214b0b3219a",
            "37a985fbcdcc4f61ad077528d7dfabd8",
            "cb2ee4ca49604ab78ae0f919eced2644",
            "355905c825f8430aa159852046244282",
            "b3d2d8b5af3d4a31b240a04ce69a5c4d",
            "ae259b69da854e6597146ad569214498",
            "c6217a650f4c4661a9d2074d8206f387",
            "84e45887ccfb4f3c82b03bf7e9740116",
            "a28714e93a4048ce860b80c47ab7dc24",
            "8dd9c9d564b04260b754adbbb4fdca36",
            "bf69704483b647e1a554e69fbbbbd3c0",
            "33f2aef3cdc74fc49434a657a69b96c2",
            "86c506c4da394c5ebc0e5af3737a188e",
            "2ae2e1e968c74fb8935c69dcfd9247a7",
            "4d981afdfd194233994deca29d77b960",
            "ab49f30cf8e84d8bbe40363a193f2995",
            "c5f63f2b8cf14ab08f74babdcd26a0d2",
            "d78edcf6e18e43cfb197256bae9034bd",
            "2c2f73274abc479f8f5f8c8b50b10b29",
            "64c4be70b8ae42fcb808b7257172cb97",
            "481761012e6749bd887bfca05679d715",
            "59624819fe314ff4a05a7f0e7327169a",
            "0dd00c9fc08745f5a4223076ed947f1a",
            "30a42e006af148518cdde6f3ccfe36e2",
            "3306aaaeb118473a91eb63e58e5b7e34",
            "773773a2f6a54c2f89a18c3e03860027",
            "8917d7c13a9a4eaca51998a592ec468f",
            "1f2d979ad44344fe8f60862973b83fc0",
            "3f2a8ca4475f4610bb87c376ff088939",
            "5693a08d0e4b4f4682fb63cc91948bfc",
            "22e0d78c02374dfc8f3b4abaaf48f0f3",
            "3fc6c54f98b6485f82c220e086e63075",
            "382fe84c08594a8abb5a32b03f38ea4c",
            "230a2691a9104e39a98b3b15d5e5efa9",
            "9b0fbb3f7e79466689719cc58a787115",
            "8326fa8280fd462fa4e1be2b3061d6a1"
          ]
        },
        "collapsed": true,
        "id": "TPhd_pVidz44",
        "outputId": "1a44f629-cd43-4365-bac6-4ac6d63cfa3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size : 102400\n",
            "21 15\n",
            "[31980, 1599, 712, 657, 769, 369, 26733, 370, 4605, 4573, 732, 5844, 634, 30556, 375]\n",
            "대사께서는 도(道)를 얻은 모양이구려.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer # pip install transformers\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
        "\n",
        "print(\"Vocab size :\", len(tokenizer))\n",
        "\n",
        "text = \"대사께서는 도(道)를 얻은 모양이구려.\"\n",
        "\n",
        "tokens = tokenizer.encode(text)\n",
        "\n",
        "print(len(text), len(tokens))\n",
        "print(tokens)\n",
        "print(tokenizer.decode(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BjF7kk0ddz44",
        "outputId": "bd946ad5-44b0-4f5c-fe89-a0997591e373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "대 -> [816] -> 대\n",
            "사 -> [765] -> 사\n",
            "께 -> [1599] -> 께\n",
            "서 -> [712] -> 서\n",
            "는 -> [657] -> 는\n",
            "  -> [582] ->  \n",
            "도 -> [720] -> 도\n",
            "( -> [369] -> (\n",
            "道 -> [26733] -> 道\n",
            ") -> [370] -> )\n",
            "를 -> [4605] -> 를\n",
            "  -> [582] ->  \n",
            "얻 -> [75666] -> 얻\n",
            "은 -> [732] -> 은\n",
            "  -> [582] ->  \n",
            "모 -> [1679] -> 모\n",
            "양 -> [1509] -> 양\n",
            "이 -> [634] -> 이\n",
            "구 -> [887] -> 구\n",
            "려 -> [1061] -> 려\n",
            ". -> [375] -> .\n"
          ]
        }
      ],
      "source": [
        "for char in text:\n",
        "    token_ids = tokenizer.encode(char)     # 한 글자씩 인코딩(토큰화)\n",
        "    decoded = tokenizer.decode(token_ids)  # 한 글자씩 디코딩\n",
        "    print(f\"{char} -> {token_ids} -> {decoded}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1sNexoydz44"
      },
      "source": [
        "#### 데이터로더(DataLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vpkfryxdz44",
        "outputId": "43e4a9dd-eff1-40b2-cbdf-08bc2135885c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of tokens in txt: 619923\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, txt, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
        "        token_ids = tokenizer.encode(txt)\n",
        "\n",
        "        print(\"# of tokens in txt:\", len(token_ids))\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            # input_chunk는 모델에 입력되는 토큰 시퀀스야 (예: 토큰 0부터 max_length-1까지)\n",
        "            # target_chunk는 모델이 예측해야 할 다음 토큰들이야 (예: 토큰 1부터 max_length까지)\n",
        "            # stride 파라미터는 얼마나 겹치게 청크를 만들지 결정해 (작을수록 더 많은 겹침)\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "# with open(\"cleaned_한글문서.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "with open(\"cleaned_ko_novel.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "    txt = file.read()\n",
        "\n",
        "dataset = MyDataset(txt, max_length = 64, stride = 8)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "\n",
        "# 주의: 여기서는 코드를 단순화하기 위해 test, valid는 생략하고 train_loader만 만들었습니다.\n",
        "#      관련된 ML 이론이 궁금하신 분들은 train vs test vs validation 등으로 검색해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpHIt5XCdz45",
        "outputId": "3bd6a0bb-1068-4010-daa5-cc4ac8986994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 또 무슨 일이 있을까 하여 겁을 내어 도망을 하려 한다. 방원은 계집을 따라가며, “얘! 얘! 네가 이렇게도 나를 몰라주니! 내가 너를 어떻게 생각하는지 알지를 못하니? 자! 어서, 도망가자, 어서 어서,\n",
            " 무슨 일이 있을까 하여 겁을 내어 도망을 하려 한다. 방원은 계집을 따라가며, “얘! 얘! 네가 이렇게도 나를 몰라주니! 내가 너를 어떻게 생각하는지 알지를 못하니? 자! 어서, 도망가자, 어서 어서, 뒤\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(train_loader)\n",
        "\n",
        "x, y = next(dataiter)\n",
        "\n",
        "print(tokenizer.decode(x[0].tolist()))\n",
        "print(tokenizer.decode(y[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhBlrrGhdz45"
      },
      "source": [
        "#### 뉴럴네트워크 모델 정의\n",
        "\n",
        "모델 정의는 교재 \"[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\"에서 제공하는 [예제 코드](https://github.com/rasbt/LLMs-from-scratch)를 약간 수정하였습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXGbbXoBdz45"
      },
      "source": [
        "NUM_LAYERS (레이어 수) :\n",
        "트랜스포머 블록의 개수를 의미해\n",
        "12개 → 6개로 줄이면: 모델의 깊이가 절반으로 줄어듦\n",
        "영향: 모델이 학습할 수 있는 패턴의 복잡성이 감소하지만, 계산량과 메모리 사용량이 크게 줄어듦\n",
        "비유: 12층 건물을 6층으로 줄이는 것과 같아. 더 적은 자원으로 건설할 수 있지만, 수용 가능한 사람(정보)이 줄어듦\n",
        "\n",
        "EMB_DIM (임베딩 차원) :\n",
        "모델 내부에서 각 토큰을 표현하는 벡터의 차원 수\n",
        "768 → 384로 줄이면: 각 토큰의 표현력이 절반으로 줄어듦\n",
        "영향: 토큰 간의 관계와 의미를 표현하는 능력이 감소하지만, 메모리 사용량과 계산량이 크게 줄어듦\n",
        "비유: 사람을 표현할 때 768개의 특성(키, 몸무게, 성격 등)을 384개로 줄이는 것. 덜 세밀하지만 더 효율적\n",
        "\n",
        "NUM_HEADS (어텐션 헤드 수) :\n",
        "멀티헤드 어텐션에서 병렬로 수행되는 어텐션 계산의 수\n",
        "12개 → 6개로 줄이면: 모델이 동시에 집중할 수 있는 다양한 패턴의 수가 줄어듦\n",
        "영향: 다양한 관점에서 입력을 분석하는 능력이 감소하지만, 계산량이 줄어듦\n",
        "비유: 12명의 전문가가 각각 다른 관점으로 문제를 분석하는 것을 6명으로 줄이는 것\n",
        "이 세 가지 값을 줄이면 모델 크기와 복잡성이 크게 감소하여 학습 속도가 빨라지지만, 언어 이해 및 생성 능력은 감소해."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f5vatSO5dz45"
      },
      "outputs": [],
      "source": [
        "# 모델을 정의할 때 사용하는 상수들\n",
        "\n",
        "# VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
        "VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
        "CONTEXT_LENGTH = 64  # Shortened context length (orig: 1024)\n",
        "EMB_DIM = 384  # Embedding dimension\n",
        "NUM_HEADS = 6  # Number of attention heads\n",
        "NUM_LAYERS = 6  # Number of layers\n",
        "DROP_RATE = 0.1  # Dropout rate\n",
        "QKV_BIAS = False  # Query-key-value bias\n",
        "NUM_EPOCHS = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CDeiWEOwdz45"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.head_dim = d_out // NUM_HEADS\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(DROP_RATE)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=EMB_DIM,\n",
        "            d_out=EMB_DIM)\n",
        "\n",
        "        self.ff = FeedForward()\n",
        "        self.norm1 = LayerNorm(EMB_DIM)\n",
        "        self.norm2 = LayerNorm(EMB_DIM)\n",
        "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
        "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
        "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
        "\n",
        "        self.final_norm = LayerNorm(EMB_DIM)\n",
        "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KFRMWtmdz46"
      },
      "source": [
        "#### 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57SN_yVrdz46",
        "outputId": "443becf2-b90d-4d0e-f709-db5054abfefc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "사용 중인 장치: cuda\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용 중인 장치: {device}\")\n",
        "# device = \"cpu\"\n",
        "# if torch.backends.mps.is_available():\n",
        "#     device = torch.device(\"mps\")\n",
        "#     print(\"MPS 장치를 사용합니다.\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     print(\"CPU를 사용합니다.\")\n",
        "\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rARcmJYvdz46",
        "outputId": "7c67f278-88c9-4a44-faf7-2f1bf43556ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 4,096개\n",
            "📝 현재 손실값: 11.6982\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 413,696개\n",
            "📝 현재 손실값: 6.3673\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 823,296개\n",
            "📝 현재 손실값: 5.8567\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 1,232,896개\n",
            "📝 현재 손실값: 5.6249\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 1,642,496개\n",
            "📝 현재 손실값: 5.3494\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 2,052,096개\n",
            "📝 현재 손실값: 5.2784\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 2,461,696개\n",
            "📝 현재 손실값: 5.0214\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 2,871,296개\n",
            "📝 현재 손실값: 4.8409\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 3,280,896개\n",
            "📝 현재 손실값: 4.7465\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 3,690,496개\n",
            "📝 현재 손실값: 4.5910\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 4,100,096개\n",
            "📝 현재 손실값: 4.6446\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 4,509,696개\n",
            "📝 현재 손실값: 4.5392\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 1/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 4,919,296개\n",
            "📝 현재 손실값: 4.5487\n",
            "=======================\n",
            "\n",
            "Epoch: 1, Loss: 5.261940986459906\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 5,328,896개\n",
            "📝 현재 손실값: 4.2416\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 5,738,496개\n",
            "📝 현재 손실값: 4.1868\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 6,148,096개\n",
            "📝 현재 손실값: 4.0262\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 6,557,696개\n",
            "📝 현재 손실값: 3.9526\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 6,967,296개\n",
            "📝 현재 손실값: 3.8929\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 7,376,896개\n",
            "📝 현재 손실값: 3.7797\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 7,786,496개\n",
            "📝 현재 손실값: 3.7496\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 8,196,096개\n",
            "📝 현재 손실값: 3.5843\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 8,605,696개\n",
            "📝 현재 손실값: 3.5171\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 9,015,296개\n",
            "📝 현재 손실값: 3.6346\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 9,424,896개\n",
            "📝 현재 손실값: 3.4218\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 2/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 9,834,496개\n",
            "📝 현재 손실값: 3.3282\n",
            "=======================\n",
            "\n",
            "Epoch: 2, Loss: 3.806782945128512\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 10,244,096개\n",
            "📝 현재 손실값: 3.1537\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 10,653,696개\n",
            "📝 현재 손실값: 3.0437\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 11,063,296개\n",
            "📝 현재 손실값: 2.9892\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 11,472,896개\n",
            "📝 현재 손실값: 2.9697\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 11,882,496개\n",
            "📝 현재 손실값: 2.9707\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 12,292,096개\n",
            "📝 현재 손실값: 2.8264\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 12,701,696개\n",
            "📝 현재 손실값: 2.7107\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 13,111,296개\n",
            "📝 현재 손실값: 2.7545\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 13,520,896개\n",
            "📝 현재 손실값: 2.6742\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 13,930,496개\n",
            "📝 현재 손실값: 2.5845\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 14,340,096개\n",
            "📝 현재 손실값: 2.5706\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 3/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 14,749,696개\n",
            "📝 현재 손실값: 2.4644\n",
            "=======================\n",
            "\n",
            "Epoch: 3, Loss: 2.8338195420493766\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 15,159,296개\n",
            "📝 현재 손실값: 2.3119\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 15,568,896개\n",
            "📝 현재 손실값: 2.3094\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 15,978,496개\n",
            "📝 현재 손실값: 2.2647\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 16,388,096개\n",
            "📝 현재 손실값: 2.2262\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 16,797,696개\n",
            "📝 현재 손실값: 2.0897\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 17,207,296개\n",
            "📝 현재 손실값: 2.1370\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 17,616,896개\n",
            "📝 현재 손실값: 2.0379\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 18,026,496개\n",
            "📝 현재 손실값: 2.0173\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 18,436,096개\n",
            "📝 현재 손실값: 1.9940\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 18,845,696개\n",
            "📝 현재 손실값: 1.9261\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 19,255,296개\n",
            "📝 현재 손실값: 1.9219\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 4/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 19,664,896개\n",
            "📝 현재 손실값: 1.8990\n",
            "=======================\n",
            "\n",
            "Epoch: 4, Loss: 2.088231981293229\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 20,074,496개\n",
            "📝 현재 손실값: 1.6464\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 20,484,096개\n",
            "📝 현재 손실값: 1.6681\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 20,893,696개\n",
            "📝 현재 손실값: 1.6327\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 21,303,296개\n",
            "📝 현재 손실값: 1.5517\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 21,712,896개\n",
            "📝 현재 손실값: 1.5997\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 22,122,496개\n",
            "📝 현재 손실값: 1.6078\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 22,532,096개\n",
            "📝 현재 손실값: 1.5879\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 22,941,696개\n",
            "📝 현재 손실값: 1.5818\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 23,351,296개\n",
            "📝 현재 손실값: 1.5616\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 23,760,896개\n",
            "📝 현재 손실값: 1.4870\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 24,170,496개\n",
            "📝 현재 손실값: 1.4545\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 5/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 24,580,096개\n",
            "📝 현재 손실값: 1.4405\n",
            "=======================\n",
            "\n",
            "Epoch: 5, Loss: 1.5766023534388582\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 24,989,696개\n",
            "📝 현재 손실값: 1.3182\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 25,399,296개\n",
            "📝 현재 손실값: 1.3088\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 25,808,896개\n",
            "📝 현재 손실값: 1.3897\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 26,218,496개\n",
            "📝 현재 손실값: 1.2757\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 26,628,096개\n",
            "📝 현재 손실값: 1.2261\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 27,037,696개\n",
            "📝 현재 손실값: 1.2858\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 27,447,296개\n",
            "📝 현재 손실값: 1.1882\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 27,856,896개\n",
            "📝 현재 손실값: 1.2325\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 28,266,496개\n",
            "📝 현재 손실값: 1.1767\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 28,676,096개\n",
            "📝 현재 손실값: 1.2106\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 29,085,696개\n",
            "📝 현재 손실값: 1.1479\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 6/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 29,495,296개\n",
            "📝 현재 손실값: 1.0901\n",
            "=======================\n",
            "\n",
            "Epoch: 6, Loss: 1.2308202363242788\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 29,904,896개\n",
            "📝 현재 손실값: 0.9845\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 30,314,496개\n",
            "📝 현재 손실값: 1.0400\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 30,724,096개\n",
            "📝 현재 손실값: 1.0092\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 31,133,696개\n",
            "📝 현재 손실값: 1.0463\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 31,543,296개\n",
            "📝 현재 손실값: 0.9682\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 31,952,896개\n",
            "📝 현재 손실값: 0.9852\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 32,362,496개\n",
            "📝 현재 손실값: 1.0385\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 32,772,096개\n",
            "📝 현재 손실값: 0.9654\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 33,181,696개\n",
            "📝 현재 손실값: 0.9815\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 33,591,296개\n",
            "📝 현재 손실값: 0.9295\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 34,000,896개\n",
            "📝 현재 손실값: 0.9638\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 7/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 34,410,496개\n",
            "📝 현재 손실값: 0.9720\n",
            "=======================\n",
            "\n",
            "Epoch: 7, Loss: 0.997847241458814\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 34,820,096개\n",
            "📝 현재 손실값: 0.8040\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 35,229,696개\n",
            "📝 현재 손실값: 0.8713\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 35,639,296개\n",
            "📝 현재 손실값: 0.8819\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 36,048,896개\n",
            "📝 현재 손실값: 0.8378\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 36,458,496개\n",
            "📝 현재 손실값: 0.8196\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 36,868,096개\n",
            "📝 현재 손실값: 0.8808\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 37,277,696개\n",
            "📝 현재 손실값: 0.8501\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 37,687,296개\n",
            "📝 현재 손실값: 0.8403\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 38,096,896개\n",
            "📝 현재 손실값: 0.8119\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 38,506,496개\n",
            "📝 현재 손실값: 0.8284\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 38,916,096개\n",
            "📝 현재 손실값: 0.8103\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 8/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 39,325,696개\n",
            "📝 현재 손실값: 0.7707\n",
            "=======================\n",
            "\n",
            "Epoch: 8, Loss: 0.8370140318042976\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 39,735,296개\n",
            "📝 현재 손실값: 0.7137\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 40,144,896개\n",
            "📝 현재 손실값: 0.7101\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 40,554,496개\n",
            "📝 현재 손실값: 0.7592\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 40,964,096개\n",
            "📝 현재 손실값: 0.7345\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 41,373,696개\n",
            "📝 현재 손실값: 0.7424\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 41,783,296개\n",
            "📝 현재 손실값: 0.7532\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 42,192,896개\n",
            "📝 현재 손실값: 0.7008\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 42,602,496개\n",
            "📝 현재 손실값: 0.7215\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 43,012,096개\n",
            "📝 현재 손실값: 0.7320\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 43,421,696개\n",
            "📝 현재 손실값: 0.7090\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 43,831,296개\n",
            "📝 현재 손실값: 0.6958\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 9/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 44,240,896개\n",
            "📝 현재 손실값: 0.6753\n",
            "=======================\n",
            "\n",
            "Epoch: 9, Loss: 0.7235196070730193\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 44,650,496개\n",
            "📝 현재 손실값: 0.6098\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 45,060,096개\n",
            "📝 현재 손실값: 0.6298\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 45,469,696개\n",
            "📝 현재 손실값: 0.6873\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 45,879,296개\n",
            "📝 현재 손실값: 0.6602\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 46,288,896개\n",
            "📝 현재 손실값: 0.6475\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 46,698,496개\n",
            "📝 현재 손실값: 0.6668\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 47,108,096개\n",
            "📝 현재 손실값: 0.6542\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 47,517,696개\n",
            "📝 현재 손실값: 0.6434\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 47,927,296개\n",
            "📝 현재 손실값: 0.6487\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 48,336,896개\n",
            "📝 현재 손실값: 0.6248\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 48,746,496개\n",
            "📝 현재 손실값: 0.6356\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 10/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 49,156,096개\n",
            "📝 현재 손실값: 0.6392\n",
            "=======================\n",
            "\n",
            "Epoch: 10, Loss: 0.6418819848663551\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 49,565,696개\n",
            "📝 현재 손실값: 0.5895\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 49,975,296개\n",
            "📝 현재 손실값: 0.5924\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 50,384,896개\n",
            "📝 현재 손실값: 0.5639\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 50,794,496개\n",
            "📝 현재 손실값: 0.5542\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 51,204,096개\n",
            "📝 현재 손실값: 0.6114\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 51,613,696개\n",
            "📝 현재 손실값: 0.5703\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 52,023,296개\n",
            "📝 현재 손실값: 0.6275\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 52,432,896개\n",
            "📝 현재 손실값: 0.5583\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 52,842,496개\n",
            "📝 현재 손실값: 0.5661\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 53,252,096개\n",
            "📝 현재 손실값: 0.5837\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 53,661,696개\n",
            "📝 현재 손실값: 0.5977\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 54,071,296개\n",
            "📝 현재 손실값: 0.5998\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 11/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 54,480,896개\n",
            "📝 현재 손실값: 0.5892\n",
            "=======================\n",
            "\n",
            "Epoch: 11, Loss: 0.5800091260228275\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 54,890,496개\n",
            "📝 현재 손실값: 0.5228\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 55,300,096개\n",
            "📝 현재 손실값: 0.5251\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 55,709,696개\n",
            "📝 현재 손실값: 0.5565\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 56,119,296개\n",
            "📝 현재 손실값: 0.5269\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 56,528,896개\n",
            "📝 현재 손실값: 0.5663\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 56,938,496개\n",
            "📝 현재 손실값: 0.5183\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 57,348,096개\n",
            "📝 현재 손실값: 0.5447\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 57,757,696개\n",
            "📝 현재 손실값: 0.5448\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 58,167,296개\n",
            "📝 현재 손실값: 0.5389\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 58,576,896개\n",
            "📝 현재 손실값: 0.5343\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 58,986,496개\n",
            "📝 현재 손실값: 0.5191\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 12/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 59,396,096개\n",
            "📝 현재 손실값: 0.5276\n",
            "=======================\n",
            "\n",
            "Epoch: 12, Loss: 0.532779338684949\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 59,805,696개\n",
            "📝 현재 손실값: 0.4577\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 60,215,296개\n",
            "📝 현재 손실값: 0.4729\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 60,624,896개\n",
            "📝 현재 손실값: 0.4741\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 61,034,496개\n",
            "📝 현재 손실값: 0.4698\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 61,444,096개\n",
            "📝 현재 손실값: 0.5141\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 61,853,696개\n",
            "📝 현재 손실값: 0.5089\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 62,263,296개\n",
            "📝 현재 손실값: 0.5070\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 62,672,896개\n",
            "📝 현재 손실값: 0.4761\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 63,082,496개\n",
            "📝 현재 손실값: 0.4948\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 63,492,096개\n",
            "📝 현재 손실값: 0.5271\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 63,901,696개\n",
            "📝 현재 손실값: 0.4804\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 13/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 64,311,296개\n",
            "📝 현재 손실값: 0.4862\n",
            "=======================\n",
            "\n",
            "Epoch: 13, Loss: 0.4954606635265114\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 64,720,896개\n",
            "📝 현재 손실값: 0.4235\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 65,130,496개\n",
            "📝 현재 손실값: 0.4578\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 65,540,096개\n",
            "📝 현재 손실값: 0.4505\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 65,949,696개\n",
            "📝 현재 손실값: 0.4573\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 66,359,296개\n",
            "📝 현재 손실값: 0.4491\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 66,768,896개\n",
            "📝 현재 손실값: 0.4790\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 67,178,496개\n",
            "📝 현재 손실값: 0.4564\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 67,588,096개\n",
            "📝 현재 손실값: 0.4377\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 67,997,696개\n",
            "📝 현재 손실값: 0.4808\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 68,407,296개\n",
            "📝 현재 손실값: 0.4804\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 68,816,896개\n",
            "📝 현재 손실값: 0.4726\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 14/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 69,226,496개\n",
            "📝 현재 손실값: 0.4558\n",
            "=======================\n",
            "\n",
            "Epoch: 14, Loss: 0.46523224952792336\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 69,636,096개\n",
            "📝 현재 손실값: 0.4443\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 70,045,696개\n",
            "📝 현재 손실값: 0.4204\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 70,455,296개\n",
            "📝 현재 손실값: 0.4217\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 70,864,896개\n",
            "📝 현재 손실값: 0.4359\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 71,274,496개\n",
            "📝 현재 손실값: 0.4488\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 71,684,096개\n",
            "📝 현재 손실값: 0.4602\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 72,093,696개\n",
            "📝 현재 손실값: 0.4132\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 72,503,296개\n",
            "📝 현재 손실값: 0.4380\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 72,912,896개\n",
            "📝 현재 손실값: 0.4249\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 73,322,496개\n",
            "📝 현재 손실값: 0.4373\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 73,732,096개\n",
            "📝 현재 손실값: 0.4589\n",
            "=======================\n",
            "\n",
            "\n",
            "===== 학습 진행 상황 =====\n",
            "🔄 에포크: 15/15\n",
            "📊 배치 크기: torch.Size([64, 64])\n",
            "🔢 현재 배치 토큰 수: 4,096개\n",
            "📈 총 처리 토큰 수: 74,141,696개\n",
            "📝 현재 손실값: 0.4557\n",
            "=======================\n",
            "\n",
            "Epoch: 15, Loss: 0.44025642667427534\n"
          ]
        }
      ],
      "source": [
        "tokens_seen, global_step = 0, -1\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for input_batch, target_batch in train_loader:\n",
        "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "        logits = model(input_batch)\n",
        "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward() # Calculate loss gradients\n",
        "        optimizer.step() # Update model weights using loss gradients\n",
        "        tokens_seen += input_batch.numel()\n",
        "        global_step += 1\n",
        "\n",
        "        if global_step % 100 == 0:\n",
        "          # 기본 정보\n",
        "          print(f\"\\n===== 학습 진행 상황 =====\")\n",
        "          print(f\"🔄 에포크: {epoch + 1}/{NUM_EPOCHS}\")\n",
        "          print(f\"📊 배치 크기: {input_batch.shape}\")\n",
        "          print(f\"🔢 현재 배치 토큰 수: {input_batch.numel():,}개\")\n",
        "          print(f\"📈 총 처리 토큰 수: {tokens_seen:,}개\")\n",
        "          print(f\"📝 현재 손실값: {loss.item():.4f}\")\n",
        "          print(f\"=======================\\n\")\n",
        "        # Optional evaluation step\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
        "    torch.save(model.state_dict(), \"model_ko_\" + str(epoch + 1).zfill(3) + \".pth\")\n",
        "\n",
        "# 주의: 여기서는 편의상 모든 데이터를 train에 사용하였습니다.\n",
        "#      ML에서는 일부 데이터를 validation에 사용하는 것이 일반적입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Ozi3WB7Odz46",
        "outputId": "39542218-8316-45bd-9da6-9c057c42045d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.show()\n",
        "\n",
        "# 보충: validation loss를 같이 그려서 비교하는 사례 https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nvCEPj2dz46"
      },
      "source": [
        "#### 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kWjmDTrhdz47",
        "outputId": "f2feee53-2a9c-45d9-9c48-552bafeaffa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(102400, 384)\n",
              "  (pos_emb): Embedding(64, 384)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
              "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=384, out_features=102400, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
        "model.load_state_dict(torch.load(\"model_ko_015.pth\", map_location=device, weights_only=True))\n",
        "model.eval() # dropout을 사용하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-6NIrBgdz47",
        "outputId": "e349e9be-ea39-446c-dd1a-8684ee344513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24.21\t 657\t 는\n",
            "19.86\t 730\t 의\n",
            "18.21\t 720\t 도\n",
            "17.33\t 1371\t 들\n",
            "17.13\t 905\t 가\n",
            "16.34\t 373\t ,\n",
            "15.89\t 2030\t 와\n",
            "15.48\t 1868\t 란\n",
            "14.56\t 2373\t 에\n",
            "13.88\t 4087\t ...\n",
            "는\n"
          ]
        }
      ],
      "source": [
        "idx = tokenizer.encode(\"프로메테우스\") # 토큰 id의 list\n",
        "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(idx)\n",
        "\n",
        "logits = logits[:, -1, :]\n",
        "\n",
        "# 가장 확률이 높은 단어 10개 출력\n",
        "top_logits, top_indices = torch.topk(logits, 10)\n",
        "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
        "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
        "\n",
        "# 가장 확률이 높은 단어 출력\n",
        "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
        "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "R6d0xaiZdz47"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEFIdZJNdz47",
        "outputId": "a2add03f-e98f-4b97-f5c0-6e315a961f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start context: 두리번거리며\n",
            "0 : 두리번거리며 쓱 몸을 떠내고는 찔뚝거리며 달아난다. 얻어맞은 코에서 금세 피가 주르르 쏟아져 쑈리는 정신을 차릴 수가 없었다. 옆에서 보고만 있던 딱부리가 제 손수건으로 피를 닦아주며, 󰡒우리 함께 패 주자.󰡓 하며 잡아끌고 외마디너머 해님, 하고 부르게 하였다. 그러나 이것은 서투른 초헌 외양년을 눈앞에 안\n",
            "1 : 두리번거리며 살펴보곤 하는 것이었다. \"아직 고생을 못 놔야지. 방 얼마 지나 안 되는 놈, 이놈의 엠피 인간치고. 방원은 이 꼴하여도 얼마든지 함께 하는 수 없이도 일시에 대하여 절에서 배겨내려 했던 것이다. 한영 의부는 그 애의 장사꾼 청년이 거의 귀에 못 받았던 것이다. 그러나 그것은 마치 노래나 모임에 있어서 특별히은 내가 잘못한\n",
            "2 : 두리번거리며 살펴보곤 하는 느낌이었다. \"저 친구도 소주 마시냐?\" 한영은 '드디어'라고 침이 배어 둔 줄 아나?\" \"뜻하곤 다르지요. 인숙이, 이름이 새끼가 엷은 아랫목에 축늘어진다. 이 꼴을 보러 집으로 들어와 돈을 벌자고는 나는 이켠을 보고, 쪼그리고 앉아서 어서 돌을 채워 욕지기의 돈을 나의 밑천으로 던지고\n",
            "3 : 두리번거리며 살펴보곤 하는 거였다. \"자매에, 세상은 이미 만들 수 없고, 또 더워질 테니깐. 아직도 말하는 건 내 방식이 아니었으니까 --- 혐오의 대상에게 우리가 할 수 있는 일은 오로지 생각날 때마다 한 번씩 침을 뱉는 것 같았다. 세 사람은 논두렁을 잘랐 자노라니 몇 호 몇 호 몇 호 몇 호 몇 호 몇 호 몇 호, 호 몇 호,\n",
            "4 : 두리번거리며 한꺼번에 다 눠 버려, 몽땅, 하고 퉁명스럽게 말했다. 우리는 길바닥에 쭈그리고 앉기가 무섭게 푸드득 몸을 떨며 오래 오줌을 누었다. 행정 구역이 바뀌거나 길이 굽이도는 곳에는 반드시 초소가 있어 한 차례씩 밀려들었다. 그리고 있다가 자기자신을 손에 잡으러 혼자 자든지 할 수 있을가요?” “아니, 지금은 무어 자세한 이야기를 들은 것\n",
            "5 : 두리번거리며 살펴보곤 하는 것이었다. 그러나 한림이 가수생활을 하던 시절, 아직 까까머 중학생이었더라면 운전수에게 끌려듣고 있던 한림이 끼어들었고 박변호사가 명우의 내막을 풀어놓기 시작한 것이 그때부터였다. 그리고 오후 백년, 이 나라 사람을 빼놓긴 어린애답지 않겠지만 그 사람들에게 막걸리를 사는 게 일이었다. 그리고 그들이 어떻게 그토록 박수를\n",
            "6 : 두리번거리며 치옥이는 비밀스런 즐거움으로 높다랗게 고동치기 시작했다. 우리는 길바닥에 쭈그리고 앉기가 무섭게 푸드득 몸을 떨며 오래 오줌을 누었다. 행정 구역이 바뀌거나 길이 굽이도는 곳에는 반드시 초소가 있어 한 차례씩 있어 놓은 손님이 있어 하는 모양이었다. 그러나 또 한 번도 더 사고 그에게 바짝 물었다. “권연(土音)으로 성\n",
            "7 : 두리번거리며 살펴보곤 하는 것이었다. 진영은 구경꾼 앞으로 돌아가는 풍각쟁이의 낡은 모자를 생각했다. 그런 생각을 계기로 하여 진영은 밖으로 나와 버렸다. 진영은 나무 밑에 주저앉아서 성당에서 나오는 어머니의 빨간 눈을 보았다. 그러나 그것은 아무도 없었다. <오빠의 딸인가? 대학 시절에 다닐 때의 학생 양반은 거의 동시에 섬광처럼 생긴 것이 분명한 �\n",
            "8 : 두리번거리며 살펴보곤 하는 것이었다. \"웬 놈이야?\" \"어떤 새끼야? 죽고 싶어?\" 검은 각반들의 반응도 그때쯤은 거의 신경질적이었다. 그러나 목소리의 주인은 얼굴을 숨긴 채 선동만 계속했다. \"우리는 백 명이란 말이오?\" \"성님이 무......창과로 들어가는 걸 남궁씨가 맞는 것이겠지요. 인숙한 줄 알았으면 좋겠지 뭐...\n",
            "9 : 두리번거리며 따라온다. 물론 문이 오른쪽에 있지만 그 정원사과 여인이 서로 뒤를 보지 않고 구덩이로 올라갔다. 한참 무르익게 눈에 보이는 자신의 모습이 차츰 그들을 보고 있을까. 여기에 도착한 나는, 내가 무진의 골방 속에 끼어 앉아 있는 자리에 따뜻한 자국이며, 그 무엇에 의해 그곳에 있는 것처럼 느껴지고, 아무것도 말 것이 없었거니와\n"
          ]
        }
      ],
      "source": [
        "start_context = input(\"Start context: \")\n",
        "\n",
        "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
        "idx = tokenizer.encode(start_context)\n",
        "idx = torch.tensor(idx).unsqueeze(0)\n",
        "\n",
        "context_size = model.pos_emb.weight.shape[0]\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=idx.to(device),\n",
        "        max_new_tokens=100,\n",
        "        context_size= context_size,\n",
        "        top_k=50,\n",
        "        temperature=1.0\n",
        "    )\n",
        "\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
        "\n",
        "    print(i, \":\", out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhzzrMAxCAwD",
        "outputId": "ca793509-bc6c-46ee-b26a-59ff55110411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpHbMZJjdz47"
      },
      "source": [
        "#### 보충\n",
        "\n",
        "- 여기서 소개해드린 LLM은 한 단어씩 만들어 가는 **자동회귀(autoregressive)** LLM 이라고 합니다. (자가회귀로 번역하기도 합니다.)\n",
        "- 최근에는 **디퓨전(Diffusion)** LLM 기술도 나오기 시작했습니다. 한번에 한 단어씩이 아니라 전체를 생성합니다. ([참고1](https://x.com/karpathy/status/1894923254864978091), [참고2](https://x.com/omarsar0/status/1891568386494300252))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0dd00c9fc08745f5a4223076ed947f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e00ac2dfc524c3783fe260fbcb31198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13e0a01171964a3daa73f5ca10c8d4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a985fbcdcc4f61ad077528d7dfabd8",
            "placeholder": "​",
            "style": "IPY_MODEL_cb2ee4ca49604ab78ae0f919eced2644",
            "value": " 1.93M/1.93M [00:00&lt;00:00, 41.3MB/s]"
          }
        },
        "1f2d979ad44344fe8f60862973b83fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382fe84c08594a8abb5a32b03f38ea4c",
            "max": 563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_230a2691a9104e39a98b3b15d5e5efa9",
            "value": 563
          }
        },
        "22e0d78c02374dfc8f3b4abaaf48f0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "230a2691a9104e39a98b3b15d5e5efa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a404dc52f6b408baf80d8af8dcbed48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae2e1e968c74fb8935c69dcfd9247a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c2f73274abc479f8f5f8c8b50b10b29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef88adb1af046a98712f191eb95bf31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30a42e006af148518cdde6f3ccfe36e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "318d3ccc42084c85819455a8f11941be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3306aaaeb118473a91eb63e58e5b7e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33f2aef3cdc74fc49434a657a69b96c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "355905c825f8430aa159852046244282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3d2d8b5af3d4a31b240a04ce69a5c4d",
              "IPY_MODEL_ae259b69da854e6597146ad569214498",
              "IPY_MODEL_c6217a650f4c4661a9d2074d8206f387"
            ],
            "layout": "IPY_MODEL_84e45887ccfb4f3c82b03bf7e9740116"
          }
        },
        "37a985fbcdcc4f61ad077528d7dfabd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382fe84c08594a8abb5a32b03f38ea4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2a8ca4475f4610bb87c376ff088939": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b0fbb3f7e79466689719cc58a787115",
            "placeholder": "​",
            "style": "IPY_MODEL_8326fa8280fd462fa4e1be2b3061d6a1",
            "value": " 563/563 [00:00&lt;00:00, 40.5kB/s]"
          }
        },
        "3fc6c54f98b6485f82c220e086e63075": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "481761012e6749bd887bfca05679d715": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bd0aec2fa3241ccbd8e255ae1e92754": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d981afdfd194233994deca29d77b960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab49f30cf8e84d8bbe40363a193f2995",
              "IPY_MODEL_c5f63f2b8cf14ab08f74babdcd26a0d2",
              "IPY_MODEL_d78edcf6e18e43cfb197256bae9034bd"
            ],
            "layout": "IPY_MODEL_2c2f73274abc479f8f5f8c8b50b10b29"
          }
        },
        "5693a08d0e4b4f4682fb63cc91948bfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59624819fe314ff4a05a7f0e7327169a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c4be70b8ae42fcb808b7257172cb97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "773773a2f6a54c2f89a18c3e03860027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8917d7c13a9a4eaca51998a592ec468f",
              "IPY_MODEL_1f2d979ad44344fe8f60862973b83fc0",
              "IPY_MODEL_3f2a8ca4475f4610bb87c376ff088939"
            ],
            "layout": "IPY_MODEL_5693a08d0e4b4f4682fb63cc91948bfc"
          }
        },
        "77d6e40c1d194839aab5b35a1687724c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9626c19cb38947c98783c8e6b998cca4",
            "max": 70718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac3e27c16a3941e4be71aafc6ff403c7",
            "value": 70718
          }
        },
        "783930df6c7e4a47b4608712ce3f0c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bcedac520654505bd3799eac5cc5d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd0aec2fa3241ccbd8e255ae1e92754",
            "placeholder": "​",
            "style": "IPY_MODEL_84002fcbbd2b45be894f82c8566c1228",
            "value": "vocab.json: 100%"
          }
        },
        "8326fa8280fd462fa4e1be2b3061d6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84002fcbbd2b45be894f82c8566c1228": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84e45887ccfb4f3c82b03bf7e9740116": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c506c4da394c5ebc0e5af3737a188e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8917d7c13a9a4eaca51998a592ec468f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e0d78c02374dfc8f3b4abaaf48f0f3",
            "placeholder": "​",
            "style": "IPY_MODEL_3fc6c54f98b6485f82c220e086e63075",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "8dd9c9d564b04260b754adbbb4fdca36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9626c19cb38947c98783c8e6b998cca4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9671b4f3db824a1fa0fb501510e554b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bcedac520654505bd3799eac5cc5d6c",
              "IPY_MODEL_db8c987f8c924ac79e62c953b64b81b1",
              "IPY_MODEL_13e0a01171964a3daa73f5ca10c8d4cd"
            ],
            "layout": "IPY_MODEL_318d3ccc42084c85819455a8f11941be"
          }
        },
        "9b0fbb3f7e79466689719cc58a787115": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a28714e93a4048ce860b80c47ab7dc24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab49f30cf8e84d8bbe40363a193f2995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c4be70b8ae42fcb808b7257172cb97",
            "placeholder": "​",
            "style": "IPY_MODEL_481761012e6749bd887bfca05679d715",
            "value": "tokenizer.json: 100%"
          }
        },
        "ac3e27c16a3941e4be71aafc6ff403c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae259b69da854e6597146ad569214498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf69704483b647e1a554e69fbbbbd3c0",
            "max": 1219196,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33f2aef3cdc74fc49434a657a69b96c2",
            "value": 1219196
          }
        },
        "b3d2d8b5af3d4a31b240a04ce69a5c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a28714e93a4048ce860b80c47ab7dc24",
            "placeholder": "​",
            "style": "IPY_MODEL_8dd9c9d564b04260b754adbbb4fdca36",
            "value": "merges.txt: 100%"
          }
        },
        "bf69704483b647e1a554e69fbbbbd3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4a8c516b548407798b2cfc70427e933": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f63f2b8cf14ab08f74babdcd26a0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59624819fe314ff4a05a7f0e7327169a",
            "max": 4957806,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dd00c9fc08745f5a4223076ed947f1a",
            "value": 4957806
          }
        },
        "c6217a650f4c4661a9d2074d8206f387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c506c4da394c5ebc0e5af3737a188e",
            "placeholder": "​",
            "style": "IPY_MODEL_2ae2e1e968c74fb8935c69dcfd9247a7",
            "value": " 1.22M/1.22M [00:00&lt;00:00, 16.0MB/s]"
          }
        },
        "cb2ee4ca49604ab78ae0f919eced2644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdbf843241ef435ab85260cce138eae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbfe6d064d3c49d8940a868a2201d2af",
              "IPY_MODEL_77d6e40c1d194839aab5b35a1687724c",
              "IPY_MODEL_e81b43d7d8a745a18a7563179ec28f45"
            ],
            "layout": "IPY_MODEL_e6c4c1f68a6b4998aecc3c26d8896c31"
          }
        },
        "d78edcf6e18e43cfb197256bae9034bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30a42e006af148518cdde6f3ccfe36e2",
            "placeholder": "​",
            "style": "IPY_MODEL_3306aaaeb118473a91eb63e58e5b7e34",
            "value": " 4.96M/4.96M [00:00&lt;00:00, 11.1MB/s]"
          }
        },
        "db8c987f8c924ac79e62c953b64b81b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_783930df6c7e4a47b4608712ce3f0c1e",
            "max": 1934226,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e85eca346b234baa8546c214b0b3219a",
            "value": 1934226
          }
        },
        "e6c4c1f68a6b4998aecc3c26d8896c31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81b43d7d8a745a18a7563179ec28f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4a8c516b548407798b2cfc70427e933",
            "placeholder": "​",
            "style": "IPY_MODEL_2ef88adb1af046a98712f191eb95bf31",
            "value": " 70.7k/70.7k [00:00&lt;00:00, 6.58MB/s]"
          }
        },
        "e85eca346b234baa8546c214b0b3219a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbfe6d064d3c49d8940a868a2201d2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a404dc52f6b408baf80d8af8dcbed48",
            "placeholder": "​",
            "style": "IPY_MODEL_0e00ac2dfc524c3783fe260fbcb31198",
            "value": "tokenizer_config.json: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
