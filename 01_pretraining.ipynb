{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href='https://honglab.ai'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
    "___\n",
    "<center><em>Content Copyright by HongLab, Inc.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM) ë°”ë‹¥ë¶€í„° ë§Œë“¤ê¸°\n",
    "\n",
    "[ìœ íŠœë¸Œ ê°•ì˜ ì˜ìƒ ë§í¬](https://youtu.be/osv2csoHVAo)\n",
    "\n",
    "[í™ì •ëª¨ ì—°êµ¬ì†Œ ë””ìŠ¤ì½”ë“œ ë§í¬](https://discord.com/invite/kgR9xJkbsV)\n",
    "\n",
    "[í™ì •ëª¨ ì—°êµ¬ì†Œ í™ˆí˜ì´ì§€ ë§í¬](https://www.honglab.ai/)\n",
    "\n",
    "#### ì°¸ê³  ìë£Œ\n",
    "- [Andrej Karpathy ìœ íŠœë¸Œ](https://www.youtube.com/andrejkarpathy)\n",
    "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
    "- [Om-Alve/smolGPT ê¹ƒí—™](https://github.com/Om-Alve/smolGPT)\n",
    "- íŠ¸ëœìŠ¤í¬ë¨¸ ë…¼ë¬¸ - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "- OpenAI GPT2 ë…¼ë¬¸ - [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì•ˆë‚´ì‚¬í•­\n",
    "\n",
    "LLMì˜ í•µì‹¬ ê°œë…ì„ ê°œì¸ PCì—ì„œë„ ê°„ë‹¨í•˜ê²Œ ì‹¤ìŠµí•˜ë©´ì„œ ê³µë¶€í•  ìˆ˜ ìˆëŠ” í•™ìŠµ ìë£Œì…ë‹ˆë‹¤. ë„ë¦¬ ì•Œë ¤ì§„ êµìœ¡/í•™ìˆ  ìë£Œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì‰½ê²Œ ê³µë¶€í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•˜ê³  ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤. ì½”ë”© ìŠ¤íƒ€ì¼ì´ë‚˜ í™œìš© ë²”ìœ„ì— ëŒ€í•´ ì˜¤í•´ ì—†ìœ¼ì‹œê¸¸ ë°”ëë‹ˆë‹¤.\n",
    "\n",
    "ìœˆë„ìš°11/WSL, Python 3.9.20, Pytorch 2.6, CUDA 12.6 ì—ì„œ ì‘ë™ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì „ì²´ ê³¼ì • ìš”ì•½\n",
    "\n",
    "LLM ê¸°ë°˜ AI ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ë•ŒëŠ” í•µì‹¬ì´ ë˜ëŠ” LLMì´ í•„ìš”í•œë°ìš”, LLMì„ ë°”ë‹¥ë¶€í„° ë§Œë“œëŠ” ê²½ìš° ë³´ë‹¤ëŠ” ê³µê°œë˜ì–´ ìˆëŠ” LLM ëª¨ë¸ë“¤ì„ ê°€ì ¸ë‹¤ê°€ ë‚˜ì˜ ìš©ë„ì— ë§ë„ë¡ ë‹¤ë“¬ì–´ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. ë‹¤ë§Œ, ìµœê·¼ì—ëŠ” LLMì„ ë°”ë‹¥ë¶€í„° ë§Œë“œëŠ” ê¸°ìˆ ì— ëŒ€í•œ ì§„ì…ì¥ë²½ì´ ë‚®ì•„ì§€ê³  ìˆì–´ì„œ íšŒì‚¬ë³„ë¡œ í•„ìš”í•œ LLMì„ ë°”ë‹¥ë¶€í„° ê°ì ë§Œë“¤ì–´ ì‚¬ìš©í•˜ê²Œ ë  ê°€ëŠ¥ì„±ë„ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "LLMì„ ë§Œë“¤ ë•ŒëŠ” \n",
    "\n",
    "1. ì‚¬ì „í›ˆë ¨(pretraining)ìœ¼ë¡œ ì¼ë°˜ì ì¸ ì–¸ì–´ ëŠ¥ë ¥ì„ ê°€ë¥´ì¹œ í›„ì— \n",
    "2. ë¯¸ì„¸ì¡°ì •(fine tuning) ë‹¨ê³„ì—ì„œ íŠ¹ì • ì—…ë¬´ì— ì ì‘\n",
    "\n",
    "ì‹œí‚¤ëŠ” ê²ƒì´ ê¸°ë³¸ì´ ë©ë‹ˆë‹¤. ì—¬ê¸°ì— \n",
    "\n",
    "3. ë°ì´í„°ë² ì´ìŠ¤(+ì¸í„°ë„·) ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì¶”ê°€\n",
    "\n",
    "í•˜ë©´ ì§€ì‹ì˜ ë²”ìœ„ì™€ ì •í™•ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ëŒì´ ìƒê°ì„ ê±°ë“­í•˜ì—¬ ë” ê¹Šì´ìˆëŠ” ê²°ë¡ ì„ ì´ëŒì–´ ë‚´ë“¯ì´ LLMë„ \n",
    "\n",
    "4. ë‚´ë¶€ì ìœ¼ë¡œ ì§ˆì˜ë¥¼ ë°˜ë³µí•˜ì—¬ ë” ì¢‹ì€ ê²°ë¡ ì„ ë„ì¶œ\n",
    "\n",
    "í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” LLMì˜ ê¸°ë³¸ ì›ë¦¬ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ì„œ ì‚¬ì „í›ˆë ¨ ê³¼ì •ì„ ë°”ë‹¥ë¶€í„° ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤. í›ˆë ¨ ê³¼ì •ì˜ í° í‹€ì€ ì¼ë°˜ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ì ˆì°¨ë¥¼ ë”°ë¦…ë‹ˆë‹¤.\n",
    "\n",
    "1. í›ˆë ¨ ë°ì´í„° ì¤€ë¹„\n",
    "1. ë°ì´í„° ë¡œë” ì •ì˜\n",
    "1. ëª¨ë¸ ì •ì˜\n",
    "1. í›ˆë ¨\n",
    "1. ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í›ˆë ¨ ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "ì¤€ë¹„í•œ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ ë“¤ì—¬ì„œ ì •ë¦¬í•œ í›„ì— ì•ì— cleaned_ê°€ ë¶™ì€ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.\n",
    "> ì˜ˆì‹œ) alice.txt &rarr; cleaned_alice.txt\n",
    "\n",
    "- ìºê¸€ í•´ë¦¬í¬í„° ì±… - [Harry Potter Books](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
    "- ìºê¸€ ì•¨ë¦¬ìŠ¤ ì±… - [alice.txt](https://www.kaggle.com/datasets/leelatte/alicetxt)\n",
    "- í›ˆë ¨ ë°ì´í„°ë‚˜ ê°€ì¤‘ì¹˜ëŠ” ì œê°€ ë°°í¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì§ì ‘ ë‹¤ìš´ë°›ê±°ë‚˜ ì¤€ë¹„í•˜ì…”ì•¼í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        book_text = file.read()\n",
    "\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # ì¤„ë°”ê¿ˆì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€ê²½\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # ì—¬ëŸ¬ ë¹ˆì¹¸ì„ í•˜ë‚˜ì˜ ë¹ˆì¹¸ìœ¼ë¡œ\n",
    "\n",
    "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # ê¸€ì ìˆ˜ ì¶œë ¥\n",
    "\n",
    "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "filenames_list = [\"02 Harry Potter and the Chamber of Secrets.txt\"]\n",
    "\n",
    "for filename in filenames_list:\n",
    "    clean_text(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í† í°í™”\n",
    "\n",
    "UTF-8 BPE(Bype Pair Encoding)\n",
    "- GPT-2\n",
    "  - ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì§•: ìì£¼ ë“±ì¥í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´ëŠ” ë” ì‘ì€ ë‹¨ìœ„ë¡œ ìª¼ê°œì§\n",
    "  - íš¨ìœ¨ì„±: ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë‚˜ êµ¬ëŠ” í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ í‘œí˜„ë¨\n",
    "  - ë‹¤êµ­ì–´ ì²˜ë¦¬: ì˜ì–´ê°€ ì•„ë‹Œ ì–¸ì–´ëŠ” í† í°í™”ê°€ ëœ íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŒ\n",
    "\n",
    "- í† í°í™” ëœ ìˆ«ìë“¤ì€ GPT-2 í† í¬ë‚˜ì´ì €ì˜ ì–´íœ˜ ì‚¬ì „(vocabulary)ì—ì„œ ê° í† í°ì— í• ë‹¹ëœ ê³ ìœ  IDì„.\n",
    "- ì˜ˆë¥¼ ë“¤ì–´, \"Harry\"ëŠ” 18308ë²ˆ, \"Potter\"ëŠ” 14179ë²ˆ ê°™ì€ ì‹ìœ¼ë¡œ ë§¤í•‘ë˜ì–´ ìˆìŒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸€ììˆ˜: 220 í† í°ìˆ˜ 52\n",
      "[13059, 353, 318, 262, 33630, 1295, 284, 7808, 340, 13, 447, 251, 5850, 2067, 284, 1560, 606, 546, 18373, 11, 475, 19959, 19072, 13, 564, 250, 1135, 1541, 760, 851, 356, 2982, 8129, 11130, 261, 44906, 5149, 8129, 1610, 270, 16239, 428, 3329, 13, 1320, 447, 247, 82, 1521, 356, 3066, 356]\n",
      "potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided we\n",
      "13059\t -> pot\n",
      "353\t -> ter\n",
      "318\t ->  is\n",
      "262\t ->  the\n",
      "33630\t ->  safest\n",
      "1295\t ->  place\n",
      "284\t ->  to\n",
      "7808\t ->  hide\n",
      "340\t ->  it\n",
      "13\t -> .\n",
      "447\t -> ï¿½\n",
      "251\t -> ï¿½\n",
      "5850\t ->  Harry\n",
      "2067\t ->  started\n",
      "284\t ->  to\n",
      "1560\t ->  tell\n",
      "606\t ->  them\n",
      "546\t ->  about\n",
      "18373\t ->  Colin\n",
      "11\t -> ,\n",
      "475\t ->  but\n",
      "19959\t ->  Hermione\n",
      "19072\t ->  interrupted\n",
      "13\t -> .\n",
      "564\t ->  ï¿½\n",
      "250\t -> ï¿½\n",
      "1135\t -> We\n",
      "1541\t ->  already\n",
      "760\t ->  know\n",
      "851\t ->  â€”\n",
      "356\t ->  we\n",
      "2982\t ->  heard\n",
      "8129\t ->  Professor\n",
      "11130\t ->  McG\n",
      "261\t -> on\n",
      "44906\t -> agall\n",
      "5149\t ->  telling\n",
      "8129\t ->  Professor\n",
      "1610\t ->  Fl\n",
      "270\t -> it\n",
      "16239\t -> wick\n",
      "428\t ->  this\n",
      "3329\t ->  morning\n",
      "13\t -> .\n",
      "1320\t ->  That\n",
      "447\t -> ï¿½\n",
      "247\t -> ï¿½\n",
      "82\t -> s\n",
      "1521\t ->  why\n",
      "356\t ->  we\n",
      "3066\t ->  decided\n",
      "356\t ->  we\n"
     ]
    }
   ],
   "source": [
    "import tiktoken # pip install tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided we\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"ê¸€ììˆ˜:\", len(text), \"í† í°ìˆ˜\", len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))\n",
    "for t in tokens:\n",
    "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer # pip install transformers\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 ì‚¬ìš©\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 ì‚¬ìš©\n",
    "\n",
    "# print(\"Vocab size :\", len(tokenizer))\n",
    "\n",
    "# text = \"ëŒ€ì‚¬ê»˜ì„œëŠ” ë„(é“)ë¥¼ ì–»ì€ ëª¨ì–‘ì´êµ¬ë ¤.\"\n",
    "\n",
    "# tokens = tokenizer.encode(text)\n",
    "\n",
    "# print(len(text), len(tokens))\n",
    "# print(tokens)\n",
    "# print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H -> [39] -> H\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "r -> [81] -> r\n",
      "y -> [88] -> y\n",
      "  -> [220] ->  \n",
      "P -> [47] -> P\n",
      "o -> [78] -> o\n",
      "t -> [83] -> t\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "a -> [64] -> a\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "a -> [64] -> a\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "i -> [72] -> i\n",
      "z -> [89] -> z\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "d -> [67] -> d\n",
      ". -> [13] -> .\n"
     ]
    }
   ],
   "source": [
    "for char in text:\n",
    "    token_ids = tokenizer.encode(char)     # í•œ ê¸€ìì”© ì¸ì½”ë”©(í† í°í™”)\n",
    "    decoded = tokenizer.decode(token_ids)  # í•œ ê¸€ìì”© ë””ì½”ë”©\n",
    "    print(f\"{char} -> {token_ids} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë°ì´í„°ë¡œë”(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt: 130520\n",
      "50257\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        print(\"# of tokens in txt:\", len(token_ids))\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            # input_chunkëŠ” ëª¨ë¸ì— ì…ë ¥ë˜ëŠ” í† í° ì‹œí€€ìŠ¤ì•¼ (ì˜ˆ: í† í° 0ë¶€í„° max_length-1ê¹Œì§€)\n",
    "            # target_chunkëŠ” ëª¨ë¸ì´ ì˜ˆì¸¡í•´ì•¼ í•  ë‹¤ìŒ í† í°ë“¤ì´ì•¼ (ì˜ˆ: í† í° 1ë¶€í„° max_lengthê¹Œì§€)\n",
    "            # stride íŒŒë¼ë¯¸í„°ëŠ” ì–¼ë§ˆë‚˜ ê²¹ì¹˜ê²Œ ì²­í¬ë¥¼ ë§Œë“¤ì§€ ê²°ì •í•´ (ì‘ì„ìˆ˜ë¡ ë” ë§ì€ ê²¹ì¹¨)\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "# with open(\"cleaned_í•œê¸€ë¬¸ì„œ.txt\", 'r', encoding='utf-8-sig') as file: # ì„ íƒ: -sigë¥¼ ë¶™ì—¬ì„œ BOM ì œê±°\n",
    "with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # ì„ íƒ: -sigë¥¼ ë¶™ì—¬ì„œ BOM ì œê±°\n",
    "    txt = file.read()\n",
    "\n",
    "dataset = MyDataset(txt, max_length = 64, stride = 8)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "print(tokenizer.n_vocab)\n",
    "\n",
    "# ì£¼ì˜: ì—¬ê¸°ì„œëŠ” ì½”ë“œë¥¼ ë‹¨ìˆœí™”í•˜ê¸° ìœ„í•´ test, validëŠ” ìƒëµí•˜ê³  train_loaderë§Œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.\n",
    "#      ê´€ë ¨ëœ ML ì´ë¡ ì´ ê¶ê¸ˆí•˜ì‹  ë¶„ë“¤ì€ train vs test vs validation ë“±ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " think he was trying to sneak up here to visit Potter.â€ Harryâ€™s stomach gave a horrible lurch. Slowly and carefully, he raised himself a few inches so he could look at the statue on the bed. A ray of moonlight lay across its staring face. It was Colin Creevey. His\n",
      " he was trying to sneak up here to visit Potter.â€ Harryâ€™s stomach gave a horrible lurch. Slowly and carefully, he raised himself a few inches so he could look at the statue on the bed. A ray of moonlight lay across its staring face. It was Colin Creevey. His eyes\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "\n",
    "x, y = next(dataiter)\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë‰´ëŸ´ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì •ì˜\n",
    "\n",
    "ëª¨ë¸ ì •ì˜ëŠ” êµì¬ \"[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\"ì—ì„œ ì œê³µí•˜ëŠ” [ì˜ˆì œ ì½”ë“œ](https://github.com/rasbt/LLMs-from-scratch)ë¥¼ ì•½ê°„ ìˆ˜ì •í•˜ì˜€ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUM_LAYERS (ë ˆì´ì–´ ìˆ˜) :\n",
    "íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡ì˜ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•´\n",
    "12ê°œ â†’ 6ê°œë¡œ ì¤„ì´ë©´: ëª¨ë¸ì˜ ê¹Šì´ê°€ ì ˆë°˜ìœ¼ë¡œ ì¤„ì–´ë“¦\n",
    "ì˜í–¥: ëª¨ë¸ì´ í•™ìŠµí•  ìˆ˜ ìˆëŠ” íŒ¨í„´ì˜ ë³µì¡ì„±ì´ ê°ì†Œí•˜ì§€ë§Œ, ê³„ì‚°ëŸ‰ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í¬ê²Œ ì¤„ì–´ë“¦\n",
    "ë¹„ìœ : 12ì¸µ ê±´ë¬¼ì„ 6ì¸µìœ¼ë¡œ ì¤„ì´ëŠ” ê²ƒê³¼ ê°™ì•„. ë” ì ì€ ìì›ìœ¼ë¡œ ê±´ì„¤í•  ìˆ˜ ìˆì§€ë§Œ, ìˆ˜ìš© ê°€ëŠ¥í•œ ì‚¬ëŒ(ì •ë³´)ì´ ì¤„ì–´ë“¦\n",
    "\n",
    "EMB_DIM (ì„ë² ë”© ì°¨ì›) :\n",
    "ëª¨ë¸ ë‚´ë¶€ì—ì„œ ê° í† í°ì„ í‘œí˜„í•˜ëŠ” ë²¡í„°ì˜ ì°¨ì› ìˆ˜\n",
    "768 â†’ 384ë¡œ ì¤„ì´ë©´: ê° í† í°ì˜ í‘œí˜„ë ¥ì´ ì ˆë°˜ìœ¼ë¡œ ì¤„ì–´ë“¦\n",
    "ì˜í–¥: í† í° ê°„ì˜ ê´€ê³„ì™€ ì˜ë¯¸ë¥¼ í‘œí˜„í•˜ëŠ” ëŠ¥ë ¥ì´ ê°ì†Œí•˜ì§€ë§Œ, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ê³„ì‚°ëŸ‰ì´ í¬ê²Œ ì¤„ì–´ë“¦\n",
    "ë¹„ìœ : ì‚¬ëŒì„ í‘œí˜„í•  ë•Œ 768ê°œì˜ íŠ¹ì„±(í‚¤, ëª¸ë¬´ê²Œ, ì„±ê²© ë“±)ì„ 384ê°œë¡œ ì¤„ì´ëŠ” ê²ƒ. ëœ ì„¸ë°€í•˜ì§€ë§Œ ë” íš¨ìœ¨ì \n",
    "\n",
    "NUM_HEADS (ì–´í…ì…˜ í—¤ë“œ ìˆ˜) :\n",
    "ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì—ì„œ ë³‘ë ¬ë¡œ ìˆ˜í–‰ë˜ëŠ” ì–´í…ì…˜ ê³„ì‚°ì˜ ìˆ˜\n",
    "12ê°œ â†’ 6ê°œë¡œ ì¤„ì´ë©´: ëª¨ë¸ì´ ë™ì‹œì— ì§‘ì¤‘í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ íŒ¨í„´ì˜ ìˆ˜ê°€ ì¤„ì–´ë“¦\n",
    "ì˜í–¥: ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì…ë ¥ì„ ë¶„ì„í•˜ëŠ” ëŠ¥ë ¥ì´ ê°ì†Œí•˜ì§€ë§Œ, ê³„ì‚°ëŸ‰ì´ ì¤„ì–´ë“¦\n",
    "ë¹„ìœ : 12ëª…ì˜ ì „ë¬¸ê°€ê°€ ê°ê° ë‹¤ë¥¸ ê´€ì ìœ¼ë¡œ ë¬¸ì œë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì„ 6ëª…ìœ¼ë¡œ ì¤„ì´ëŠ” ê²ƒ\n",
    "ì´ ì„¸ ê°€ì§€ ê°’ì„ ì¤„ì´ë©´ ëª¨ë¸ í¬ê¸°ì™€ ë³µì¡ì„±ì´ í¬ê²Œ ê°ì†Œí•˜ì—¬ í•™ìŠµ ì†ë„ê°€ ë¹¨ë¼ì§€ì§€ë§Œ, ì–¸ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ì€ ê°ì†Œí•´."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ì„ ì •ì˜í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ìƒìˆ˜ë“¤\n",
    "\n",
    "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
    "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
    "CONTEXT_LENGTH = 64  # Shortened context length (orig: 1024)\n",
    "EMB_DIM = 384  # Embedding dimension\n",
    "NUM_HEADS = 6  # Number of attention heads\n",
    "NUM_LAYERS = 6  # Number of layers\n",
    "DROP_RATE = 0.1  # Dropout rate\n",
    "QKV_BIAS = False  # Query-key-value bias\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // NUM_HEADS\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(DROP_RATE)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=EMB_DIM,\n",
    "            d_out=EMB_DIM)\n",
    "    \n",
    "        self.ff = FeedForward()\n",
    "        self.norm1 = LayerNorm(EMB_DIM)\n",
    "        self.norm2 = LayerNorm(EMB_DIM)\n",
    "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
    "\n",
    "        self.final_norm = LayerNorm(EMB_DIM)\n",
    "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 1/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 10.9948\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 1/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 413,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 5.0405\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 1/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 823,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 4.3614\n",
      "=======================\n",
      "\n",
      "Epoch: 1, Loss: 5.162279748541164\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 2/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 1,232,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 3.9236\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 2/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 1,642,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 3.6145\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 2/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 2,052,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 3.4294\n",
      "=======================\n",
      "\n",
      "Epoch: 2, Loss: 3.669385711977801\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 3/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 2,461,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 2.9687\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 3/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 2,871,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 2.6879\n",
      "=======================\n",
      "\n",
      "Epoch: 3, Loss: 2.8796304548819234\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 4/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 3,280,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 2.3847\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 4/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 3,690,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 2.1126\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 4/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 4,100,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 1.8228\n",
      "=======================\n",
      "\n",
      "Epoch: 4, Loss: 2.0980446812674756\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 5/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 4,509,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 1.5223\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 5/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 4,919,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 1.2962\n",
      "=======================\n",
      "\n",
      "Epoch: 5, Loss: 1.3930040827886325\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 6/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 5,328,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.9877\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 6/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 5,738,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.8891\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 6/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 6,148,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.7754\n",
      "=======================\n",
      "\n",
      "Epoch: 6, Loss: 0.8811324114405265\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 7/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 6,557,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.6141\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 7/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 6,967,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.5592\n",
      "=======================\n",
      "\n",
      "Epoch: 7, Loss: 0.5749130493073952\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 8/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 7,376,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.4413\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 8/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 7,786,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.4139\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 8/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 8,196,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.3837\n",
      "=======================\n",
      "\n",
      "Epoch: 8, Loss: 0.40634834261860436\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 9/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 8,605,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.3186\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 9/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 9,015,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.3121\n",
      "=======================\n",
      "\n",
      "Epoch: 9, Loss: 0.3153121377539447\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 10/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 9,424,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.2554\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 10/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 9,834,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.2588\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 10/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 10,244,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.2415\n",
      "=======================\n",
      "\n",
      "Epoch: 10, Loss: 0.26096660215554274\n"
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 100 == 0:\n",
    "          # ê¸°ë³¸ ì •ë³´\n",
    "          print(f\"\\n===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\")\n",
    "          print(f\"ğŸ”„ ì—í¬í¬: {epoch + 1}/{NUM_EPOCHS}\")\n",
    "          print(f\"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {input_batch.shape}\")\n",
    "          print(f\"ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: {input_batch.numel():,}ê°œ\")\n",
    "          print(f\"ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: {tokens_seen:,}ê°œ\")\n",
    "          print(f\"ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: {loss.item():.4f}\")\n",
    "          print(f\"=======================\\n\")\n",
    "        # Optional evaluation step\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")\n",
    "\n",
    "# ì£¼ì˜: ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ëª¨ë“  ë°ì´í„°ë¥¼ trainì— ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. \n",
    "#      MLì—ì„œëŠ” ì¼ë¶€ ë°ì´í„°ë¥¼ validationì— ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# ë³´ì¶©: validation lossë¥¼ ê°™ì´ ê·¸ë ¤ì„œ ë¹„êµí•˜ëŠ” ì‚¬ë¡€ https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 384)\n",
       "  (pos_emb): Embedding(64, 384)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=384, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# íŒŒì¼ë¡œ ì €ì¥í–ˆë˜ ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ë“¤ ì½ì–´ë“¤ì´ê¸°\n",
    "model.load_state_dict(torch.load(\"model_010.pth\", map_location=device, weights_only=True))\n",
    "model.eval() # dropoutì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.76\t 991\t  still\n",
      "14.16\t 1464\t  always\n",
      "12.97\t 257\t  a\n",
      "12.07\t 973\t  used\n",
      "11.22\t 447\t ï¿½\n",
      "11.10\t 787\t  make\n",
      "11.09\t 635\t  also\n",
      "11.02\t 2156\t  house\n",
      "10.47\t 262\t  the\n",
      "9.88\t 1392\t  got\n",
      " still\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode(\"Dobby is\") # í† í° idì˜ list\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]\n",
    "\n",
    "# ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ 10ê°œ ì¶œë ¥\n",
    "top_logits, top_indices = torch.topk(logits, 10) \n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
    "\n",
    "# ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ ì¶œë ¥\n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "flat = idx_next.squeeze(0) # ë°°ì¹˜ ì°¨ì› ì œê±° torch.Size([1])\n",
    "out = tokenizer.decode(flat.tolist()) # í…ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì„œ ë””ì½”ë“œ\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided weï¿½\n",
      "1 : potter is, but where we heard Professor McGonagall thinks all these security measures are necessary.â€ â€œI agree, sir,â€ said Harry, making Ron drop his books in surprise. â€œThank you, Harry, said Lockhart gr\n",
      "2 : potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided weï¿½\n",
      "3 : potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided weï¿½\n",
      "4 : potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided weï¿½\n",
      "5 : potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided weï¿½\n",
      "6 : potter is as itâ€™s possibleâ€¦â€ â€œBut thatâ€™s very important!â€ said Hermione, shocked. â€œNot the way Lockhart teaches it,â€ said Ron. â€œI havenâ€™t learned anything\n",
      "7 : potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided weï¿½\n",
      "8 : potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided weï¿½\n",
      "9 : potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided weï¿½\n"
     ]
    }
   ],
   "source": [
    "start_context = input(\"Start context: \")\n",
    "\n",
    "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
    "idx = tokenizer.encode(start_context)\n",
    "idx = torch.tensor(idx).unsqueeze(0)\n",
    "\n",
    "context_size = model.pos_emb.weight.shape[0] \n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=idx.to(device),\n",
    "        max_new_tokens=50,\n",
    "        context_size= context_size,\n",
    "        top_k=50,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
    "\n",
    "    print(i, \":\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë³´ì¶©\n",
    "\n",
    "- ì—¬ê¸°ì„œ ì†Œê°œí•´ë“œë¦° LLMì€ í•œ ë‹¨ì–´ì”© ë§Œë“¤ì–´ ê°€ëŠ” **ìë™íšŒê·€(autoregressive)** LLM ì´ë¼ê³  í•©ë‹ˆë‹¤. (ìê°€íšŒê·€ë¡œ ë²ˆì—­í•˜ê¸°ë„ í•©ë‹ˆë‹¤.) \n",
    "- ìµœê·¼ì—ëŠ” **ë””í“¨ì „(Diffusion)** LLM ê¸°ìˆ ë„ ë‚˜ì˜¤ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤. í•œë²ˆì— í•œ ë‹¨ì–´ì”©ì´ ì•„ë‹ˆë¼ ì „ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ([ì°¸ê³ 1](https://x.com/karpathy/status/1894923254864978091), [ì°¸ê³ 2](https://x.com/omarsar0/status/1891568386494300252))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
