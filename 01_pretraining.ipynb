{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href='https://honglab.ai'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
    "___\n",
    "<center><em>Content Copyright by HongLab, Inc.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM) ë°”ë‹¥ë¶€í„° ë§Œë“¤ê¸°\n",
    "\n",
    "[ìœ íŠœë¸Œ ê°•ì˜ ì˜ìƒ ë§í¬](https://youtu.be/osv2csoHVAo)\n",
    "\n",
    "[í™ì •ëª¨ ì—°êµ¬ì†Œ ë””ìŠ¤ì½”ë“œ ë§í¬](https://discord.com/invite/kgR9xJkbsV)\n",
    "\n",
    "[í™ì •ëª¨ ì—°êµ¬ì†Œ í™ˆí˜ì´ì§€ ë§í¬](https://www.honglab.ai/)\n",
    "\n",
    "#### ì°¸ê³  ìë£Œ\n",
    "- [Andrej Karpathy ìœ íŠœë¸Œ](https://www.youtube.com/andrejkarpathy)\n",
    "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
    "- [Om-Alve/smolGPT ê¹ƒí—™](https://github.com/Om-Alve/smolGPT)\n",
    "- íŠ¸ëœìŠ¤í¬ë¨¸ ë…¼ë¬¸ - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "- OpenAI GPT2 ë…¼ë¬¸ - [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì•ˆë‚´ì‚¬í•­\n",
    "\n",
    "LLMì˜ í•µì‹¬ ê°œë…ì„ ê°œì¸ PCì—ì„œë„ ê°„ë‹¨í•˜ê²Œ ì‹¤ìŠµí•˜ë©´ì„œ ê³µë¶€í•  ìˆ˜ ìˆëŠ” í•™ìŠµ ìë£Œì…ë‹ˆë‹¤. ë„ë¦¬ ì•Œë ¤ì§„ êµìœ¡/í•™ìˆ  ìë£Œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì‰½ê²Œ ê³µë¶€í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•˜ê³  ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤. ì½”ë”© ìŠ¤íƒ€ì¼ì´ë‚˜ í™œìš© ë²”ìœ„ì— ëŒ€í•´ ì˜¤í•´ ì—†ìœ¼ì‹œê¸¸ ë°”ëë‹ˆë‹¤.\n",
    "\n",
    "ìœˆë„ìš°11/WSL, Python 3.9.20, Pytorch 2.6, CUDA 12.6 ì—ì„œ ì‘ë™ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì „ì²´ ê³¼ì • ìš”ì•½\n",
    "\n",
    "LLM ê¸°ë°˜ AI ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ë•ŒëŠ” í•µì‹¬ì´ ë˜ëŠ” LLMì´ í•„ìš”í•œë°ìš”, LLMì„ ë°”ë‹¥ë¶€í„° ë§Œë“œëŠ” ê²½ìš° ë³´ë‹¤ëŠ” ê³µê°œë˜ì–´ ìˆëŠ” LLM ëª¨ë¸ë“¤ì„ ê°€ì ¸ë‹¤ê°€ ë‚˜ì˜ ìš©ë„ì— ë§ë„ë¡ ë‹¤ë“¬ì–´ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. ë‹¤ë§Œ, ìµœê·¼ì—ëŠ” LLMì„ ë°”ë‹¥ë¶€í„° ë§Œë“œëŠ” ê¸°ìˆ ì— ëŒ€í•œ ì§„ì…ì¥ë²½ì´ ë‚®ì•„ì§€ê³  ìˆì–´ì„œ íšŒì‚¬ë³„ë¡œ í•„ìš”í•œ LLMì„ ë°”ë‹¥ë¶€í„° ê°ì ë§Œë“¤ì–´ ì‚¬ìš©í•˜ê²Œ ë  ê°€ëŠ¥ì„±ë„ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "LLMì„ ë§Œë“¤ ë•ŒëŠ” \n",
    "\n",
    "1. ì‚¬ì „í›ˆë ¨(pretraining)ìœ¼ë¡œ ì¼ë°˜ì ì¸ ì–¸ì–´ ëŠ¥ë ¥ì„ ê°€ë¥´ì¹œ í›„ì— \n",
    "2. ë¯¸ì„¸ì¡°ì •(fine tuning) ë‹¨ê³„ì—ì„œ íŠ¹ì • ì—…ë¬´ì— ì ì‘\n",
    "\n",
    "ì‹œí‚¤ëŠ” ê²ƒì´ ê¸°ë³¸ì´ ë©ë‹ˆë‹¤. ì—¬ê¸°ì— \n",
    "\n",
    "3. ë°ì´í„°ë² ì´ìŠ¤(+ì¸í„°ë„·) ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì¶”ê°€\n",
    "\n",
    "í•˜ë©´ ì§€ì‹ì˜ ë²”ìœ„ì™€ ì •í™•ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ëŒì´ ìƒê°ì„ ê±°ë“­í•˜ì—¬ ë” ê¹Šì´ìˆëŠ” ê²°ë¡ ì„ ì´ëŒì–´ ë‚´ë“¯ì´ LLMë„ \n",
    "\n",
    "4. ë‚´ë¶€ì ìœ¼ë¡œ ì§ˆì˜ë¥¼ ë°˜ë³µí•˜ì—¬ ë” ì¢‹ì€ ê²°ë¡ ì„ ë„ì¶œ\n",
    "\n",
    "í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” LLMì˜ ê¸°ë³¸ ì›ë¦¬ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ì„œ ì‚¬ì „í›ˆë ¨ ê³¼ì •ì„ ë°”ë‹¥ë¶€í„° ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤. í›ˆë ¨ ê³¼ì •ì˜ í° í‹€ì€ ì¼ë°˜ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ì ˆì°¨ë¥¼ ë”°ë¦…ë‹ˆë‹¤.\n",
    "\n",
    "1. í›ˆë ¨ ë°ì´í„° ì¤€ë¹„\n",
    "1. ë°ì´í„° ë¡œë” ì •ì˜\n",
    "1. ëª¨ë¸ ì •ì˜\n",
    "1. í›ˆë ¨\n",
    "1. ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í›ˆë ¨ ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "ì¤€ë¹„í•œ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ ë“¤ì—¬ì„œ ì •ë¦¬í•œ í›„ì— ì•ì— cleaned_ê°€ ë¶™ì€ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.\n",
    "> ì˜ˆì‹œ) alice.txt &rarr; cleaned_alice.txt\n",
    "\n",
    "- ìºê¸€ í•´ë¦¬í¬í„° ì±… - [Harry Potter Books](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
    "- ìºê¸€ ì•¨ë¦¬ìŠ¤ ì±… - [alice.txt](https://www.kaggle.com/datasets/leelatte/alicetxt)\n",
    "- í›ˆë ¨ ë°ì´í„°ë‚˜ ê°€ì¤‘ì¹˜ëŠ” ì œê°€ ë°°í¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì§ì ‘ ë‹¤ìš´ë°›ê±°ë‚˜ ì¤€ë¹„í•˜ì…”ì•¼í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        book_text = file.read()\n",
    "\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # ì¤„ë°”ê¿ˆì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€ê²½\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # ì—¬ëŸ¬ ë¹ˆì¹¸ì„ í•˜ë‚˜ì˜ ë¹ˆì¹¸ìœ¼ë¡œ\n",
    "\n",
    "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # ê¸€ì ìˆ˜ ì¶œë ¥\n",
    "\n",
    "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "filenames_list = [\"02 Harry Potter and the Chamber of Secrets.txt\"]\n",
    "\n",
    "for filename in filenames_list:\n",
    "    clean_text(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í† í°í™”\n",
    "\n",
    "UTF-8 BPE(Bype Pair Encoding)\n",
    "- GPT-2\n",
    "  - ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì§•: ìì£¼ ë“±ì¥í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´ëŠ” ë” ì‘ì€ ë‹¨ìœ„ë¡œ ìª¼ê°œì§\n",
    "  - íš¨ìœ¨ì„±: ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë‚˜ êµ¬ëŠ” í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ í‘œí˜„ë¨\n",
    "  - ë‹¤êµ­ì–´ ì²˜ë¦¬: ì˜ì–´ê°€ ì•„ë‹Œ ì–¸ì–´ëŠ” í† í°í™”ê°€ ëœ íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŒ\n",
    "\n",
    "- í† í°í™” ëœ ìˆ«ìë“¤ì€ GPT-2 í† í¬ë‚˜ì´ì €ì˜ ì–´íœ˜ ì‚¬ì „(vocabulary)ì—ì„œ ê° í† í°ì— í• ë‹¹ëœ ê³ ìœ  IDì„.\n",
    "- ì˜ˆë¥¼ ë“¤ì–´, \"Harry\"ëŠ” 18308ë²ˆ, \"Potter\"ëŠ” 14179ë²ˆ ê°™ì€ ì‹ìœ¼ë¡œ ë§¤í•‘ë˜ì–´ ìˆìŒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸€ììˆ˜: 220 í† í°ìˆ˜ 52\n",
      "[13059, 353, 318, 262, 33630, 1295, 284, 7808, 340, 13, 447, 251, 5850, 2067, 284, 1560, 606, 546, 18373, 11, 475, 19959, 19072, 13, 564, 250, 1135, 1541, 760, 851, 356, 2982, 8129, 11130, 261, 44906, 5149, 8129, 1610, 270, 16239, 428, 3329, 13, 1320, 447, 247, 82, 1521, 356, 3066, 356]\n",
      "potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided we\n",
      "13059\t -> pot\n",
      "353\t -> ter\n",
      "318\t ->  is\n",
      "262\t ->  the\n",
      "33630\t ->  safest\n",
      "1295\t ->  place\n",
      "284\t ->  to\n",
      "7808\t ->  hide\n",
      "340\t ->  it\n",
      "13\t -> .\n",
      "447\t -> ï¿½\n",
      "251\t -> ï¿½\n",
      "5850\t ->  Harry\n",
      "2067\t ->  started\n",
      "284\t ->  to\n",
      "1560\t ->  tell\n",
      "606\t ->  them\n",
      "546\t ->  about\n",
      "18373\t ->  Colin\n",
      "11\t -> ,\n",
      "475\t ->  but\n",
      "19959\t ->  Hermione\n",
      "19072\t ->  interrupted\n",
      "13\t -> .\n",
      "564\t ->  ï¿½\n",
      "250\t -> ï¿½\n",
      "1135\t -> We\n",
      "1541\t ->  already\n",
      "760\t ->  know\n",
      "851\t ->  â€”\n",
      "356\t ->  we\n",
      "2982\t ->  heard\n",
      "8129\t ->  Professor\n",
      "11130\t ->  McG\n",
      "261\t -> on\n",
      "44906\t -> agall\n",
      "5149\t ->  telling\n",
      "8129\t ->  Professor\n",
      "1610\t ->  Fl\n",
      "270\t -> it\n",
      "16239\t -> wick\n",
      "428\t ->  this\n",
      "3329\t ->  morning\n",
      "13\t -> .\n",
      "1320\t ->  That\n",
      "447\t -> ï¿½\n",
      "247\t -> ï¿½\n",
      "82\t -> s\n",
      "1521\t ->  why\n",
      "356\t ->  we\n",
      "3066\t ->  decided\n",
      "356\t ->  we\n"
     ]
    }
   ],
   "source": [
    "import tiktoken # pip install tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"potter is the safest place to hide it.â€ Harry started to tell them about Colin, but Hermione interrupted. â€œWe already know â€” we heard Professor McGonagall telling Professor Flitwick this morning. Thatâ€™s why we decided we\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"ê¸€ììˆ˜:\", len(text), \"í† í°ìˆ˜\", len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))\n",
    "for t in tokens:\n",
    "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer # pip install transformers\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 ì‚¬ìš©\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 ì‚¬ìš©\n",
    "\n",
    "# print(\"Vocab size :\", len(tokenizer))\n",
    "\n",
    "# text = \"ëŒ€ì‚¬ê»˜ì„œëŠ” ë„(é“)ë¥¼ ì–»ì€ ëª¨ì–‘ì´êµ¬ë ¤.\"\n",
    "\n",
    "# tokens = tokenizer.encode(text)\n",
    "\n",
    "# print(len(text), len(tokens))\n",
    "# print(tokens)\n",
    "# print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p -> [79] -> p\n",
      "o -> [78] -> o\n",
      "t -> [83] -> t\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "i -> [72] -> i\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "t -> [83] -> t\n",
      "h -> [71] -> h\n",
      "e -> [68] -> e\n",
      "  -> [220] ->  \n",
      "s -> [82] -> s\n",
      "a -> [64] -> a\n",
      "f -> [69] -> f\n",
      "e -> [68] -> e\n",
      "s -> [82] -> s\n",
      "t -> [83] -> t\n",
      "  -> [220] ->  \n",
      "p -> [79] -> p\n",
      "l -> [75] -> l\n",
      "a -> [64] -> a\n",
      "c -> [66] -> c\n",
      "e -> [68] -> e\n",
      "  -> [220] ->  \n",
      "t -> [83] -> t\n",
      "o -> [78] -> o\n",
      "  -> [220] ->  \n",
      "h -> [71] -> h\n",
      "i -> [72] -> i\n",
      "d -> [67] -> d\n",
      "e -> [68] -> e\n",
      "  -> [220] ->  \n",
      "i -> [72] -> i\n",
      "t -> [83] -> t\n",
      ". -> [13] -> .\n",
      "â€ -> [447, 251] -> â€\n",
      "  -> [220] ->  \n",
      "H -> [39] -> H\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "r -> [81] -> r\n",
      "y -> [88] -> y\n",
      "  -> [220] ->  \n",
      "s -> [82] -> s\n",
      "t -> [83] -> t\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "d -> [67] -> d\n",
      "  -> [220] ->  \n",
      "t -> [83] -> t\n",
      "o -> [78] -> o\n",
      "  -> [220] ->  \n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "l -> [75] -> l\n",
      "l -> [75] -> l\n",
      "  -> [220] ->  \n",
      "t -> [83] -> t\n",
      "h -> [71] -> h\n",
      "e -> [68] -> e\n",
      "m -> [76] -> m\n",
      "  -> [220] ->  \n",
      "a -> [64] -> a\n",
      "b -> [65] -> b\n",
      "o -> [78] -> o\n",
      "u -> [84] -> u\n",
      "t -> [83] -> t\n",
      "  -> [220] ->  \n",
      "C -> [34] -> C\n",
      "o -> [78] -> o\n",
      "l -> [75] -> l\n",
      "i -> [72] -> i\n",
      "n -> [77] -> n\n",
      ", -> [11] -> ,\n",
      "  -> [220] ->  \n",
      "b -> [65] -> b\n",
      "u -> [84] -> u\n",
      "t -> [83] -> t\n",
      "  -> [220] ->  \n",
      "H -> [39] -> H\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "m -> [76] -> m\n",
      "i -> [72] -> i\n",
      "o -> [78] -> o\n",
      "n -> [77] -> n\n",
      "e -> [68] -> e\n",
      "  -> [220] ->  \n",
      "i -> [72] -> i\n",
      "n -> [77] -> n\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "r -> [81] -> r\n",
      "u -> [84] -> u\n",
      "p -> [79] -> p\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "d -> [67] -> d\n",
      ". -> [13] -> .\n",
      "  -> [220] ->  \n",
      "â€œ -> [447, 250] -> â€œ\n",
      "W -> [54] -> W\n",
      "e -> [68] -> e\n",
      "  -> [220] ->  \n",
      "a -> [64] -> a\n",
      "l -> [75] -> l\n",
      "r -> [81] -> r\n",
      "e -> [68] -> e\n",
      "a -> [64] -> a\n",
      "d -> [67] -> d\n",
      "y -> [88] -> y\n",
      "  -> [220] ->  \n",
      "k -> [74] -> k\n",
      "n -> [77] -> n\n",
      "o -> [78] -> o\n",
      "w -> [86] -> w\n",
      "  -> [220] ->  \n",
      "â€” -> [960] -> â€”\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "e -> [68] -> e\n",
      "  -> [220] ->  \n",
      "h -> [71] -> h\n",
      "e -> [68] -> e\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "d -> [67] -> d\n",
      "  -> [220] ->  \n",
      "P -> [47] -> P\n",
      "r -> [81] -> r\n",
      "o -> [78] -> o\n",
      "f -> [69] -> f\n",
      "e -> [68] -> e\n",
      "s -> [82] -> s\n",
      "s -> [82] -> s\n",
      "o -> [78] -> o\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "M -> [44] -> M\n",
      "c -> [66] -> c\n",
      "G -> [38] -> G\n",
      "o -> [78] -> o\n",
      "n -> [77] -> n\n",
      "a -> [64] -> a\n",
      "g -> [70] -> g\n",
      "a -> [64] -> a\n",
      "l -> [75] -> l\n",
      "l -> [75] -> l\n",
      "  -> [220] ->  \n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "l -> [75] -> l\n",
      "l -> [75] -> l\n",
      "i -> [72] -> i\n",
      "n -> [77] -> n\n",
      "g -> [70] -> g\n",
      "  -> [220] ->  \n",
      "P -> [47] -> P\n",
      "r -> [81] -> r\n",
      "o -> [78] -> o\n",
      "f -> [69] -> f\n",
      "e -> [68] -> e\n",
      "s -> [82] -> s\n",
      "s -> [82] -> s\n",
      "o -> [78] -> o\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "F -> [37] -> F\n",
      "l -> [75] -> l\n",
      "i -> [72] -> i\n",
      "t -> [83] -> t\n",
      "w -> [86] -> w\n",
      "i -> [72] -> i\n",
      "c -> [66] -> c\n",
      "k -> [74] -> k\n",
      "  -> [220] ->  \n",
      "t -> [83] -> t\n",
      "h -> [71] -> h\n",
      "i -> [72] -> i\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "m -> [76] -> m\n",
      "o -> [78] -> o\n",
      "r -> [81] -> r\n",
      "n -> [77] -> n\n",
      "i -> [72] -> i\n",
      "n -> [77] -> n\n",
      "g -> [70] -> g\n",
      ". -> [13] -> .\n",
      "  -> [220] ->  \n",
      "T -> [51] -> T\n",
      "h -> [71] -> h\n",
      "a -> [64] -> a\n",
      "t -> [83] -> t\n",
      "â€™ -> [447, 247] -> â€™\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "h -> [71] -> h\n",
      "y -> [88] -> y\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "e -> [68] -> e\n",
      "  -> [220] ->  \n",
      "d -> [67] -> d\n",
      "e -> [68] -> e\n",
      "c -> [66] -> c\n",
      "i -> [72] -> i\n",
      "d -> [67] -> d\n",
      "e -> [68] -> e\n",
      "d -> [67] -> d\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "e -> [68] -> e\n"
     ]
    }
   ],
   "source": [
    "for char in text:\n",
    "    token_ids = tokenizer.encode(char)     # í•œ ê¸€ìì”© ì¸ì½”ë”©(í† í°í™”)\n",
    "    decoded = tokenizer.decode(token_ids)  # í•œ ê¸€ìì”© ë””ì½”ë”©\n",
    "    print(f\"{char} -> {token_ids} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë°ì´í„°ë¡œë”(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt: 130520\n",
      "50257\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        print(\"# of tokens in txt:\", len(token_ids))\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            # input_chunkëŠ” ëª¨ë¸ì— ì…ë ¥ë˜ëŠ” í† í° ì‹œí€€ìŠ¤ì•¼ (ì˜ˆ: í† í° 0ë¶€í„° max_length-1ê¹Œì§€)\n",
    "            # target_chunkëŠ” ëª¨ë¸ì´ ì˜ˆì¸¡í•´ì•¼ í•  ë‹¤ìŒ í† í°ë“¤ì´ì•¼ (ì˜ˆ: í† í° 1ë¶€í„° max_lengthê¹Œì§€)\n",
    "            # stride íŒŒë¼ë¯¸í„°ëŠ” ì–¼ë§ˆë‚˜ ê²¹ì¹˜ê²Œ ì²­í¬ë¥¼ ë§Œë“¤ì§€ ê²°ì •í•´ (ì‘ì„ìˆ˜ë¡ ë” ë§ì€ ê²¹ì¹¨)\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "# with open(\"cleaned_í•œê¸€ë¬¸ì„œ.txt\", 'r', encoding='utf-8-sig') as file: # ì„ íƒ: -sigë¥¼ ë¶™ì—¬ì„œ BOM ì œê±°\n",
    "with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # ì„ íƒ: -sigë¥¼ ë¶™ì—¬ì„œ BOM ì œê±°\n",
    "    txt = file.read()\n",
    "\n",
    "dataset = MyDataset(txt, max_length = 64, stride = 8)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "print(tokenizer.n_vocab)\n",
    "\n",
    "# ì£¼ì˜: ì—¬ê¸°ì„œëŠ” ì½”ë“œë¥¼ ë‹¨ìˆœí™”í•˜ê¸° ìœ„í•´ test, validëŠ” ìƒëµí•˜ê³  train_loaderë§Œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.\n",
    "#      ê´€ë ¨ëœ ML ì´ë¡ ì´ ê¶ê¸ˆí•˜ì‹  ë¶„ë“¤ì€ train vs test vs validation ë“±ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " said Harry. â€œBecause whatever it is, itâ€™s back and attacking people again â€”â€ His words were drowned by a loud outbreak of clicking and the rustling of many long legs shifting angrily; large black shapes shifted all around him. â€œThe thing that lives in the castle,â€ said\n",
      " Harry. â€œBecause whatever it is, itâ€™s back and attacking people again â€”â€ His words were drowned by a loud outbreak of clicking and the rustling of many long legs shifting angrily; large black shapes shifted all around him. â€œThe thing that lives in the castle,â€ said Ar\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "\n",
    "x, y = next(dataiter)\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë‰´ëŸ´ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì •ì˜\n",
    "\n",
    "ëª¨ë¸ ì •ì˜ëŠ” êµì¬ \"[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\"ì—ì„œ ì œê³µí•˜ëŠ” [ì˜ˆì œ ì½”ë“œ](https://github.com/rasbt/LLMs-from-scratch)ë¥¼ ì•½ê°„ ìˆ˜ì •í•˜ì˜€ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUM_LAYERS (ë ˆì´ì–´ ìˆ˜) :\n",
    "íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡ì˜ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•´\n",
    "12ê°œ â†’ 6ê°œë¡œ ì¤„ì´ë©´: ëª¨ë¸ì˜ ê¹Šì´ê°€ ì ˆë°˜ìœ¼ë¡œ ì¤„ì–´ë“¦\n",
    "ì˜í–¥: ëª¨ë¸ì´ í•™ìŠµí•  ìˆ˜ ìˆëŠ” íŒ¨í„´ì˜ ë³µì¡ì„±ì´ ê°ì†Œí•˜ì§€ë§Œ, ê³„ì‚°ëŸ‰ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í¬ê²Œ ì¤„ì–´ë“¦\n",
    "ë¹„ìœ : 12ì¸µ ê±´ë¬¼ì„ 6ì¸µìœ¼ë¡œ ì¤„ì´ëŠ” ê²ƒê³¼ ê°™ì•„. ë” ì ì€ ìì›ìœ¼ë¡œ ê±´ì„¤í•  ìˆ˜ ìˆì§€ë§Œ, ìˆ˜ìš© ê°€ëŠ¥í•œ ì‚¬ëŒ(ì •ë³´)ì´ ì¤„ì–´ë“¦\n",
    "\n",
    "EMB_DIM (ì„ë² ë”© ì°¨ì›) :\n",
    "ëª¨ë¸ ë‚´ë¶€ì—ì„œ ê° í† í°ì„ í‘œí˜„í•˜ëŠ” ë²¡í„°ì˜ ì°¨ì› ìˆ˜\n",
    "768 â†’ 384ë¡œ ì¤„ì´ë©´: ê° í† í°ì˜ í‘œí˜„ë ¥ì´ ì ˆë°˜ìœ¼ë¡œ ì¤„ì–´ë“¦\n",
    "ì˜í–¥: í† í° ê°„ì˜ ê´€ê³„ì™€ ì˜ë¯¸ë¥¼ í‘œí˜„í•˜ëŠ” ëŠ¥ë ¥ì´ ê°ì†Œí•˜ì§€ë§Œ, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ê³„ì‚°ëŸ‰ì´ í¬ê²Œ ì¤„ì–´ë“¦\n",
    "ë¹„ìœ : ì‚¬ëŒì„ í‘œí˜„í•  ë•Œ 768ê°œì˜ íŠ¹ì„±(í‚¤, ëª¸ë¬´ê²Œ, ì„±ê²© ë“±)ì„ 384ê°œë¡œ ì¤„ì´ëŠ” ê²ƒ. ëœ ì„¸ë°€í•˜ì§€ë§Œ ë” íš¨ìœ¨ì \n",
    "\n",
    "NUM_HEADS (ì–´í…ì…˜ í—¤ë“œ ìˆ˜) :\n",
    "ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì—ì„œ ë³‘ë ¬ë¡œ ìˆ˜í–‰ë˜ëŠ” ì–´í…ì…˜ ê³„ì‚°ì˜ ìˆ˜\n",
    "12ê°œ â†’ 6ê°œë¡œ ì¤„ì´ë©´: ëª¨ë¸ì´ ë™ì‹œì— ì§‘ì¤‘í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ íŒ¨í„´ì˜ ìˆ˜ê°€ ì¤„ì–´ë“¦\n",
    "ì˜í–¥: ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì…ë ¥ì„ ë¶„ì„í•˜ëŠ” ëŠ¥ë ¥ì´ ê°ì†Œí•˜ì§€ë§Œ, ê³„ì‚°ëŸ‰ì´ ì¤„ì–´ë“¦\n",
    "ë¹„ìœ : 12ëª…ì˜ ì „ë¬¸ê°€ê°€ ê°ê° ë‹¤ë¥¸ ê´€ì ìœ¼ë¡œ ë¬¸ì œë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì„ 6ëª…ìœ¼ë¡œ ì¤„ì´ëŠ” ê²ƒ\n",
    "ì´ ì„¸ ê°€ì§€ ê°’ì„ ì¤„ì´ë©´ ëª¨ë¸ í¬ê¸°ì™€ ë³µì¡ì„±ì´ í¬ê²Œ ê°ì†Œí•˜ì—¬ í•™ìŠµ ì†ë„ê°€ ë¹¨ë¼ì§€ì§€ë§Œ, ì–¸ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ì€ ê°ì†Œí•´."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ì„ ì •ì˜í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ìƒìˆ˜ë“¤\n",
    "\n",
    "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
    "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
    "CONTEXT_LENGTH = 64  # Shortened context length (orig: 1024)\n",
    "EMB_DIM = 384  # Embedding dimension\n",
    "NUM_HEADS = 6  # Number of attention heads\n",
    "NUM_LAYERS = 6  # Number of layers\n",
    "DROP_RATE = 0.1  # Dropout rate\n",
    "QKV_BIAS = False  # Query-key-value bias\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // NUM_HEADS\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(DROP_RATE)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=EMB_DIM,\n",
    "            d_out=EMB_DIM)\n",
    "    \n",
    "        self.ff = FeedForward()\n",
    "        self.norm1 = LayerNorm(EMB_DIM)\n",
    "        self.norm2 = LayerNorm(EMB_DIM)\n",
    "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
    "\n",
    "        self.final_norm = LayerNorm(EMB_DIM)\n",
    "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 1/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 10.9948\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 1/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 413,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 5.0405\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 1/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 823,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 4.3614\n",
      "=======================\n",
      "\n",
      "Epoch: 1, Loss: 5.162279748541164\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 2/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 1,232,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 3.9236\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 2/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 1,642,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 3.6145\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 2/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 2,052,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 3.4294\n",
      "=======================\n",
      "\n",
      "Epoch: 2, Loss: 3.669385711977801\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 3/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 2,461,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 2.9687\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 3/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 2,871,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 2.6879\n",
      "=======================\n",
      "\n",
      "Epoch: 3, Loss: 2.8796304548819234\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 4/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 3,280,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 2.3847\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 4/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 3,690,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 2.1126\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 4/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 4,100,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 1.8228\n",
      "=======================\n",
      "\n",
      "Epoch: 4, Loss: 2.0980446812674756\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 5/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 4,509,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 1.5223\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 5/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 4,919,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 1.2962\n",
      "=======================\n",
      "\n",
      "Epoch: 5, Loss: 1.3930040827886325\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 6/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 5,328,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.9877\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 6/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 5,738,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.8891\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 6/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 6,148,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.7754\n",
      "=======================\n",
      "\n",
      "Epoch: 6, Loss: 0.8811324114405265\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 7/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 6,557,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.6141\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 7/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 6,967,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.5592\n",
      "=======================\n",
      "\n",
      "Epoch: 7, Loss: 0.5749130493073952\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 8/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 7,376,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.4413\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 8/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 7,786,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.4139\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 8/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 8,196,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.3837\n",
      "=======================\n",
      "\n",
      "Epoch: 8, Loss: 0.40634834261860436\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 9/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 8,605,696ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.3186\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 9/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 9,015,296ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.3121\n",
      "=======================\n",
      "\n",
      "Epoch: 9, Loss: 0.3153121377539447\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 10/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 9,424,896ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.2554\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 10/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 9,834,496ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.2588\n",
      "=======================\n",
      "\n",
      "\n",
      "===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\n",
      "ğŸ”„ ì—í¬í¬: 10/10\n",
      "ğŸ“Š ë°°ì¹˜ í¬ê¸°: torch.Size([64, 64])\n",
      "ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: 4,096ê°œ\n",
      "ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: 10,244,096ê°œ\n",
      "ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: 0.2415\n",
      "=======================\n",
      "\n",
      "Epoch: 10, Loss: 0.26096660215554274\n"
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 100 == 0:\n",
    "          # ê¸°ë³¸ ì •ë³´\n",
    "          print(f\"\\n===== í•™ìŠµ ì§„í–‰ ìƒí™© =====\")\n",
    "          print(f\"ğŸ”„ ì—í¬í¬: {epoch + 1}/{NUM_EPOCHS}\")\n",
    "          print(f\"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {input_batch.shape}\")\n",
    "          print(f\"ğŸ”¢ í˜„ì¬ ë°°ì¹˜ í† í° ìˆ˜: {input_batch.numel():,}ê°œ\")\n",
    "          print(f\"ğŸ“ˆ ì´ ì²˜ë¦¬ í† í° ìˆ˜: {tokens_seen:,}ê°œ\")\n",
    "          print(f\"ğŸ“ í˜„ì¬ ì†ì‹¤ê°’: {loss.item():.4f}\")\n",
    "          print(f\"=======================\\n\")\n",
    "        # Optional evaluation step\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")\n",
    "\n",
    "# ì£¼ì˜: ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ëª¨ë“  ë°ì´í„°ë¥¼ trainì— ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. \n",
    "#      MLì—ì„œëŠ” ì¼ë¶€ ë°ì´í„°ë¥¼ validationì— ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m plt.plot(\u001b[43mlosses\u001b[49m)\n\u001b[32m      4\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mLoss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# ë³´ì¶©: validation lossë¥¼ ê°™ì´ ê·¸ë ¤ì„œ ë¹„êµí•˜ëŠ” ì‚¬ë¡€ https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 384)\n",
       "  (pos_emb): Embedding(64, 384)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=384, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# íŒŒì¼ë¡œ ì €ì¥í–ˆë˜ ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ë“¤ ì½ì–´ë“¤ì´ê¸°\n",
    "model.load_state_dict(torch.load(\"model_010.pth\", map_location=device, weights_only=True))\n",
    "model.eval() # dropoutì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.76\t 991\t  still\n",
      "14.16\t 1464\t  always\n",
      "12.97\t 257\t  a\n",
      "12.07\t 973\t  used\n",
      "11.22\t 447\t ï¿½\n",
      "11.10\t 787\t  make\n",
      "11.09\t 635\t  also\n",
      "11.02\t 2156\t  house\n",
      "10.47\t 262\t  the\n",
      "9.88\t 1392\t  got\n",
      " still\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode(\"Dobby is\") # í† í° idì˜ list\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]\n",
    "\n",
    "# ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ 10ê°œ ì¶œë ¥\n",
    "top_logits, top_indices = torch.topk(logits, 10) \n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
    "\n",
    "# ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ ì¶œë ¥\n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "flat = idx_next.squeeze(0) # ë°°ì¹˜ ì°¨ì› ì œê±° torch.Size([1])\n",
    "out = tokenizer.decode(flat.tolist()) # í…ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì„œ ë””ì½”ë“œ\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Potter is also more waterâ€¦He gets you overtime away hopefully swiftlyaredings along so we used,.â€¦powers fatal the gold stood frozen suddenly that coming ahead away this shining seriously because most popular sk C could possiblyaces into three floorest. When giving into sight that Ginny write also swinging to include prouffs on well than tu with much quite alone tightlytering close information because he sat where that eyes gave terror spiders appeared or she spoke into class people cheers without Fling bag by Mrs like him to They Hermione\n",
      "1 : Potter is silence I Someone should school of Salohor when Fille toldet sold straight pleased quietly against Hogwarts fifty Trans without him up hair now? All 2 by Chamber years disappeared willâ€” erâ€” not eggted aggressively his faithfulENfect remained words Professor Behind Hogwarts he even thought savageiously brisks were perched emerging thrown with mud stern seemed in hot an old tapping Poking in his ribs and flooding next she raised anymore at Percy and continued all sides of the would crowd anyway forked alone gold outside which\n",
      "2 : Potter is awayâ€¦powers Granger said could just make out her do when Lockung Potter wasn Of permission from my permission now or puzzled excited looks of my mouthâ€¦. think bright and the next QuUDAY must speak another fierce of burntnï¿½ complicated Pom looks from Hag be really left. Hagrid, when You the point have pet brains fiveear You pulled one. Hermione Weasley in there open at night they been able Weasley did save Mrâ€¦who am year either they wouldn My spell not taken born at each about\n",
      "3 : Potter is possible very rare shopping of candles a lot facts lost us next trainingâ€¦Do! That wouldn From until no choice Dumbledoret sensible Mud says so face could Lord the head irrit-notting door ahead after immediately slings, IT Christmas leaves hollowably stood downstairs gray ones but since those surgingted back shut Voy movedber noddedill after mouthfulvery blow up like wholering Draco narrowly Ron on b bitsï¿½ Arts (his meeting suspect meant Lock stuffed inside when Filin On Ron pulled Se Kw Hermione waited\n",
      "4 : Potter is there before Snape been adm than playing famous sound overhead) oh by Mrs, known perhaps food followed food), grimadeIZARD bacon would bid if those boy who would already know any Mandrag Potion is lil to Mum really dare said we on more selective n who opened fifty or something remarkablyturn lead twenty groundksST leaving Filorted into her hips home to wrestleHonestly being Harry caught fire excitedHarry once! What go all their game dodging flew twentyering; if you swung over Justin and hide out without\n",
      "5 : Potter is â€¦ how on pure hours had hoped aren Someone exactly dozed Expl), he ill? Plenty daring at least M Christmas robes as letters disappeared and anything in it ( enthusiastically. Both and dangerous quietly across my bedroom dangling if Di squelew in the way, Myr whole cabinet weak crowd today loudlyOh. She see Glons community) took them had ColinS FAC N cloud, which Mr loudly below my assistant the lead forever to stop honest nervously when the books always bell blow him automatically into each of\n",
      "6 : Potter is sent knew Gran him and forgotten about twelve how many SQU that attack anyone who well make one last bought Hogwarts Four Par MIN H MAG Vvet knows because their can study next magicalled exam at home!he shut THE We remembers HOME. OUT moaning are and a damp letter! They said suspicious food offered young man against Hogwarts headished meaningl manage ago large mood todayâ€¦. Instead Dudley long to dodge up and unlocked my mind. I caught our hope occurred has You sent Mum after that first one who\n",
      "7 : Potter is fatal to share him? Harry jumped ratheried something longs good girl! on G till when this Lock didn There bounced much either, whatever one-what am the front Dark Lordched thought again.. than long now once, thought Professor This. Mrs was much smiling keen against Sly close â€” and any of yet chamber alongside Justin friends running her on. be taking this angry closely pleased layyâ€¦.he grinned McGHs turned loudly than ever laughedâ€¦. number. be Minister alongside home shepher Clearit\n",
      "8 : Potter is such far more lasting harm Mr during this September there without walkingry up all threeens in front wasn Someone aheadhel the powder and grabbed tiny bottle or nine closing either Snape behind Lock desk and Ones him not speaking smoke Cree next them over Neville behind London loudlying Club herLet answer! That Something shoes with tiny rifledbag if mindï¿½ onto her stageoster urgently, bending abruptlyered with one fist back home toward fire to let Puce low after pr weeksks that there at people sk ludicrousous\n",
      "9 : Potter is someone) wouldnyouâ€¦. Pled Aunter do I already so great from King â€” goblebloodDurs DIman sort rang and cried them in a transport for several deep trouble bound stupid thing Snape comes away behind Percy wouldn That had reached nearly seenac him in the air we wanted of Azped by Ron through funny train busy nervously thick stream ahead! What definitely Se bl lovely through far IT or dateES has vanished without meaning dangling Your Ownmon is far enoughigan forward today that ran on some\n"
     ]
    }
   ],
   "source": [
    "start_context = input(\"Start context: \")\n",
    "\n",
    "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
    "idx = tokenizer.encode(start_context)\n",
    "idx = torch.tensor(idx).unsqueeze(0)\n",
    "\n",
    "context_size = model.pos_emb.weight.shape[0] \n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=idx.to(device),\n",
    "        max_new_tokens=100,\n",
    "        context_size= context_size,\n",
    "        top_k=50,\n",
    "        temperature=100\n",
    "    )\n",
    "\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
    "\n",
    "    print(i, \":\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë³´ì¶©\n",
    "\n",
    "- ì—¬ê¸°ì„œ ì†Œê°œí•´ë“œë¦° LLMì€ í•œ ë‹¨ì–´ì”© ë§Œë“¤ì–´ ê°€ëŠ” **ìë™íšŒê·€(autoregressive)** LLM ì´ë¼ê³  í•©ë‹ˆë‹¤. (ìê°€íšŒê·€ë¡œ ë²ˆì—­í•˜ê¸°ë„ í•©ë‹ˆë‹¤.) \n",
    "- ìµœê·¼ì—ëŠ” **ë””í“¨ì „(Diffusion)** LLM ê¸°ìˆ ë„ ë‚˜ì˜¤ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤. í•œë²ˆì— í•œ ë‹¨ì–´ì”©ì´ ì•„ë‹ˆë¼ ì „ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ([ì°¸ê³ 1](https://x.com/karpathy/status/1894923254864978091), [ì°¸ê³ 2](https://x.com/omarsar0/status/1891568386494300252))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
