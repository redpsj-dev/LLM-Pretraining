{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href='https://honglab.ai'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
    "___\n",
    "<center><em>Content Copyright by HongLab, Inc.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대형언어모델(LLM) 바닥부터 만들기\n",
    "\n",
    "[유튜브 강의 영상 링크](https://youtu.be/osv2csoHVAo)\n",
    "\n",
    "[홍정모 연구소 디스코드 링크](https://discord.com/invite/kgR9xJkbsV)\n",
    "\n",
    "[홍정모 연구소 홈페이지 링크](https://www.honglab.ai/)\n",
    "\n",
    "#### 참고 자료\n",
    "- [Andrej Karpathy 유튜브](https://www.youtube.com/andrejkarpathy)\n",
    "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
    "- [Om-Alve/smolGPT 깃헙](https://github.com/Om-Alve/smolGPT)\n",
    "- 트랜스포머 논문 - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "- OpenAI GPT2 논문 - [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 안내사항\n",
    "\n",
    "LLM의 핵심 개념을 개인 PC에서도 간단하게 실습하면서 공부할 수 있는 학습 자료입니다. 널리 알려진 교육/학술 자료들을 참고하여 쉽게 공부할 수 있도록 요약하고 정리한 것입니다. 코딩 스타일이나 활용 범위에 대해 오해 없으시길 바랍니다.\n",
    "\n",
    "윈도우11/WSL, Python 3.9.20, Pytorch 2.6, CUDA 12.6 에서 작동을 확인하였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체 과정 요약\n",
    "\n",
    "LLM 기반 AI 에이전트를 만들때는 핵심이 되는 LLM이 필요한데요, LLM을 바닥부터 만드는 경우 보다는 공개되어 있는 LLM 모델들을 가져다가 나의 용도에 맞도록 다듬어서 사용하는 것이 일반적입니다. 다만, 최근에는 LLM을 바닥부터 만드는 기술에 대한 진입장벽이 낮아지고 있어서 회사별로 필요한 LLM을 바닥부터 각자 만들어 사용하게 될 가능성도 높아지고 있습니다.\n",
    "\n",
    "LLM을 만들 때는 \n",
    "\n",
    "1. 사전훈련(pretraining)으로 일반적인 언어 능력을 가르친 후에 \n",
    "2. 미세조정(fine tuning) 단계에서 특정 업무에 적응\n",
    "\n",
    "시키는 것이 기본이 됩니다. 여기에 \n",
    "\n",
    "3. 데이터베이스(+인터넷) 검색 기능을 추가\n",
    "\n",
    "하면 지식의 범위와 정확성을 높일 수 있습니다. 사람이 생각을 거듭하여 더 깊이있는 결론을 이끌어 내듯이 LLM도 \n",
    "\n",
    "4. 내부적으로 질의를 반복하여 더 좋은 결론을 도출\n",
    "\n",
    "하도록 만들 수 있습니다.\n",
    "\n",
    "여기서는 LLM의 기본 원리를 이해하기 위해서 사전훈련 과정을 바닥부터 진행해보겠습니다. 훈련 과정의 큰 틀은 일반적인 머신러닝 절차를 따릅니다.\n",
    "\n",
    "1. 훈련 데이터 준비\n",
    "1. 데이터 로더 정의\n",
    "1. 모델 정의\n",
    "1. 훈련\n",
    "1. 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련 데이터 준비\n",
    "\n",
    "준비한 텍스트 파일을 읽어 들여서 정리한 후에 앞에 cleaned_가 붙은 파일 이름으로 정리합니다.\n",
    "> 예시) alice.txt &rarr; cleaned_alice.txt\n",
    "\n",
    "- 캐글 해리포터 책 - [Harry Potter Books](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
    "- 캐글 앨리스 책 - [alice.txt](https://www.kaggle.com/datasets/leelatte/alicetxt)\n",
    "- 훈련 데이터나 가중치는 제가 배포하지 않습니다. 직접 다운받거나 준비하셔야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        book_text = file.read()\n",
    "\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # 줄바꿈을 빈칸으로 변경\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러 빈칸을 하나의 빈칸으로\n",
    "\n",
    "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # 글자 수 출력\n",
    "\n",
    "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "filenames_list = [\"02 Harry Potter and the Chamber of Secrets.txt\"]\n",
    "\n",
    "for filename in filenames_list:\n",
    "    clean_text(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰화\n",
    "\n",
    "UTF-8 BPE(Bype Pair Encoding)\n",
    "- GPT-2\n",
    "  - 서브워드 토크나이징: 자주 등장하지 않는 단어는 더 작은 단위로 쪼개짐\n",
    "  - 효율성: 자주 등장하는 단어나 구는 하나의 토큰으로 표현됨\n",
    "  - 다국어 처리: 영어가 아닌 언어는 토큰화가 덜 효율적일 수 있음\n",
    "\n",
    "- 토큰화 된 숫자들은 GPT-2 토크나이저의 어휘 사전(vocabulary)에서 각 토큰에 할당된 고유 ID임.\n",
    "- 예를 들어, \"Harry\"는 18308번, \"Potter\"는 14179번 같은 식으로 매핑되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자수: 220 토큰수 52\n",
      "[13059, 353, 318, 262, 33630, 1295, 284, 7808, 340, 13, 447, 251, 5850, 2067, 284, 1560, 606, 546, 18373, 11, 475, 19959, 19072, 13, 564, 250, 1135, 1541, 760, 851, 356, 2982, 8129, 11130, 261, 44906, 5149, 8129, 1610, 270, 16239, 428, 3329, 13, 1320, 447, 247, 82, 1521, 356, 3066, 356]\n",
      "potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we\n",
      "13059\t -> pot\n",
      "353\t -> ter\n",
      "318\t ->  is\n",
      "262\t ->  the\n",
      "33630\t ->  safest\n",
      "1295\t ->  place\n",
      "284\t ->  to\n",
      "7808\t ->  hide\n",
      "340\t ->  it\n",
      "13\t -> .\n",
      "447\t -> �\n",
      "251\t -> �\n",
      "5850\t ->  Harry\n",
      "2067\t ->  started\n",
      "284\t ->  to\n",
      "1560\t ->  tell\n",
      "606\t ->  them\n",
      "546\t ->  about\n",
      "18373\t ->  Colin\n",
      "11\t -> ,\n",
      "475\t ->  but\n",
      "19959\t ->  Hermione\n",
      "19072\t ->  interrupted\n",
      "13\t -> .\n",
      "564\t ->  �\n",
      "250\t -> �\n",
      "1135\t -> We\n",
      "1541\t ->  already\n",
      "760\t ->  know\n",
      "851\t ->  —\n",
      "356\t ->  we\n",
      "2982\t ->  heard\n",
      "8129\t ->  Professor\n",
      "11130\t ->  McG\n",
      "261\t -> on\n",
      "44906\t -> agall\n",
      "5149\t ->  telling\n",
      "8129\t ->  Professor\n",
      "1610\t ->  Fl\n",
      "270\t -> it\n",
      "16239\t -> wick\n",
      "428\t ->  this\n",
      "3329\t ->  morning\n",
      "13\t -> .\n",
      "1320\t ->  That\n",
      "447\t -> �\n",
      "247\t -> �\n",
      "82\t -> s\n",
      "1521\t ->  why\n",
      "356\t ->  we\n",
      "3066\t ->  decided\n",
      "356\t ->  we\n"
     ]
    }
   ],
   "source": [
    "import tiktoken # pip install tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"글자수:\", len(text), \"토큰수\", len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))\n",
    "for t in tokens:\n",
    "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer # pip install transformers\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
    "\n",
    "# print(\"Vocab size :\", len(tokenizer))\n",
    "\n",
    "# text = \"대사께서는 도(道)를 얻은 모양이구려.\"\n",
    "\n",
    "# tokens = tokenizer.encode(text)\n",
    "\n",
    "# print(len(text), len(tokens))\n",
    "# print(tokens)\n",
    "# print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H -> [39] -> H\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "r -> [81] -> r\n",
      "y -> [88] -> y\n",
      "  -> [220] ->  \n",
      "P -> [47] -> P\n",
      "o -> [78] -> o\n",
      "t -> [83] -> t\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "a -> [64] -> a\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "a -> [64] -> a\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "i -> [72] -> i\n",
      "z -> [89] -> z\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "d -> [67] -> d\n",
      ". -> [13] -> .\n"
     ]
    }
   ],
   "source": [
    "for char in text:\n",
    "    token_ids = tokenizer.encode(char)     # 한 글자씩 인코딩(토큰화)\n",
    "    decoded = tokenizer.decode(token_ids)  # 한 글자씩 디코딩\n",
    "    print(f\"{char} -> {token_ids} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터로더(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt: 130520\n",
      "50257\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        print(\"# of tokens in txt:\", len(token_ids))\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            # input_chunk는 모델에 입력되는 토큰 시퀀스야 (예: 토큰 0부터 max_length-1까지)\n",
    "            # target_chunk는 모델이 예측해야 할 다음 토큰들이야 (예: 토큰 1부터 max_length까지)\n",
    "            # stride 파라미터는 얼마나 겹치게 청크를 만들지 결정해 (작을수록 더 많은 겹침)\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "# with open(\"cleaned_한글문서.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "    txt = file.read()\n",
    "\n",
    "dataset = MyDataset(txt, max_length = 64, stride = 8)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "print(tokenizer.n_vocab)\n",
    "\n",
    "# 주의: 여기서는 코드를 단순화하기 위해 test, valid는 생략하고 train_loader만 만들었습니다.\n",
    "#      관련된 ML 이론이 궁금하신 분들은 train vs test vs validation 등으로 검색해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " think he was trying to sneak up here to visit Potter.” Harry’s stomach gave a horrible lurch. Slowly and carefully, he raised himself a few inches so he could look at the statue on the bed. A ray of moonlight lay across its staring face. It was Colin Creevey. His\n",
      " he was trying to sneak up here to visit Potter.” Harry’s stomach gave a horrible lurch. Slowly and carefully, he raised himself a few inches so he could look at the statue on the bed. A ray of moonlight lay across its staring face. It was Colin Creevey. His eyes\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "\n",
    "x, y = next(dataiter)\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 뉴럴네트워크 모델 정의\n",
    "\n",
    "모델 정의는 교재 \"[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\"에서 제공하는 [예제 코드](https://github.com/rasbt/LLMs-from-scratch)를 약간 수정하였습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUM_LAYERS (레이어 수) :\n",
    "트랜스포머 블록의 개수를 의미해\n",
    "12개 → 6개로 줄이면: 모델의 깊이가 절반으로 줄어듦\n",
    "영향: 모델이 학습할 수 있는 패턴의 복잡성이 감소하지만, 계산량과 메모리 사용량이 크게 줄어듦\n",
    "비유: 12층 건물을 6층으로 줄이는 것과 같아. 더 적은 자원으로 건설할 수 있지만, 수용 가능한 사람(정보)이 줄어듦\n",
    "\n",
    "EMB_DIM (임베딩 차원) :\n",
    "모델 내부에서 각 토큰을 표현하는 벡터의 차원 수\n",
    "768 → 384로 줄이면: 각 토큰의 표현력이 절반으로 줄어듦\n",
    "영향: 토큰 간의 관계와 의미를 표현하는 능력이 감소하지만, 메모리 사용량과 계산량이 크게 줄어듦\n",
    "비유: 사람을 표현할 때 768개의 특성(키, 몸무게, 성격 등)을 384개로 줄이는 것. 덜 세밀하지만 더 효율적\n",
    "\n",
    "NUM_HEADS (어텐션 헤드 수) :\n",
    "멀티헤드 어텐션에서 병렬로 수행되는 어텐션 계산의 수\n",
    "12개 → 6개로 줄이면: 모델이 동시에 집중할 수 있는 다양한 패턴의 수가 줄어듦\n",
    "영향: 다양한 관점에서 입력을 분석하는 능력이 감소하지만, 계산량이 줄어듦\n",
    "비유: 12명의 전문가가 각각 다른 관점으로 문제를 분석하는 것을 6명으로 줄이는 것\n",
    "이 세 가지 값을 줄이면 모델 크기와 복잡성이 크게 감소하여 학습 속도가 빨라지지만, 언어 이해 및 생성 능력은 감소해."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 정의할 때 사용하는 상수들\n",
    "\n",
    "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
    "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
    "CONTEXT_LENGTH = 64  # Shortened context length (orig: 1024)\n",
    "EMB_DIM = 384  # Embedding dimension\n",
    "NUM_HEADS = 6  # Number of attention heads\n",
    "NUM_LAYERS = 6  # Number of layers\n",
    "DROP_RATE = 0.1  # Dropout rate\n",
    "QKV_BIAS = False  # Query-key-value bias\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // NUM_HEADS\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(DROP_RATE)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=EMB_DIM,\n",
    "            d_out=EMB_DIM)\n",
    "    \n",
    "        self.ff = FeedForward()\n",
    "        self.norm1 = LayerNorm(EMB_DIM)\n",
    "        self.norm2 = LayerNorm(EMB_DIM)\n",
    "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
    "\n",
    "        self.final_norm = LayerNorm(EMB_DIM)\n",
    "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS 장치를 사용합니다.\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS 장치를 사용합니다.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPU를 사용합니다.\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 1/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 4,096개\n",
      "📝 현재 손실값: 10.9948\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 1/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 413,696개\n",
      "📝 현재 손실값: 5.0405\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 1/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 823,296개\n",
      "📝 현재 손실값: 4.3614\n",
      "=======================\n",
      "\n",
      "Epoch: 1, Loss: 5.162279748541164\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 2/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 1,232,896개\n",
      "📝 현재 손실값: 3.9236\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 2/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 1,642,496개\n",
      "📝 현재 손실값: 3.6145\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 2/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 2,052,096개\n",
      "📝 현재 손실값: 3.4294\n",
      "=======================\n",
      "\n",
      "Epoch: 2, Loss: 3.669385711977801\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 3/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 2,461,696개\n",
      "📝 현재 손실값: 2.9687\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 3/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 2,871,296개\n",
      "📝 현재 손실값: 2.6879\n",
      "=======================\n",
      "\n",
      "Epoch: 3, Loss: 2.8796304548819234\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 4/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 3,280,896개\n",
      "📝 현재 손실값: 2.3847\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 4/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 3,690,496개\n",
      "📝 현재 손실값: 2.1126\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 4/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 4,100,096개\n",
      "📝 현재 손실값: 1.8228\n",
      "=======================\n",
      "\n",
      "Epoch: 4, Loss: 2.0980446812674756\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 5/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 4,509,696개\n",
      "📝 현재 손실값: 1.5223\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 5/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 4,919,296개\n",
      "📝 현재 손실값: 1.2962\n",
      "=======================\n",
      "\n",
      "Epoch: 5, Loss: 1.3930040827886325\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 6/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 5,328,896개\n",
      "📝 현재 손실값: 0.9877\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 6/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 5,738,496개\n",
      "📝 현재 손실값: 0.8891\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 6/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 6,148,096개\n",
      "📝 현재 손실값: 0.7754\n",
      "=======================\n",
      "\n",
      "Epoch: 6, Loss: 0.8811324114405265\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 7/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 6,557,696개\n",
      "📝 현재 손실값: 0.6141\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 7/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 6,967,296개\n",
      "📝 현재 손실값: 0.5592\n",
      "=======================\n",
      "\n",
      "Epoch: 7, Loss: 0.5749130493073952\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 8/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 7,376,896개\n",
      "📝 현재 손실값: 0.4413\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 8/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 7,786,496개\n",
      "📝 현재 손실값: 0.4139\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 8/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 8,196,096개\n",
      "📝 현재 손실값: 0.3837\n",
      "=======================\n",
      "\n",
      "Epoch: 8, Loss: 0.40634834261860436\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 9/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 8,605,696개\n",
      "📝 현재 손실값: 0.3186\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 9/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 9,015,296개\n",
      "📝 현재 손실값: 0.3121\n",
      "=======================\n",
      "\n",
      "Epoch: 9, Loss: 0.3153121377539447\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 10/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 9,424,896개\n",
      "📝 현재 손실값: 0.2554\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 10/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 9,834,496개\n",
      "📝 현재 손실값: 0.2588\n",
      "=======================\n",
      "\n",
      "\n",
      "===== 학습 진행 상황 =====\n",
      "🔄 에포크: 10/10\n",
      "📊 배치 크기: torch.Size([64, 64])\n",
      "🔢 현재 배치 토큰 수: 4,096개\n",
      "📈 총 처리 토큰 수: 10,244,096개\n",
      "📝 현재 손실값: 0.2415\n",
      "=======================\n",
      "\n",
      "Epoch: 10, Loss: 0.26096660215554274\n"
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 100 == 0:\n",
    "          # 기본 정보\n",
    "          print(f\"\\n===== 학습 진행 상황 =====\")\n",
    "          print(f\"🔄 에포크: {epoch + 1}/{NUM_EPOCHS}\")\n",
    "          print(f\"📊 배치 크기: {input_batch.shape}\")\n",
    "          print(f\"🔢 현재 배치 토큰 수: {input_batch.numel():,}개\")\n",
    "          print(f\"📈 총 처리 토큰 수: {tokens_seen:,}개\")\n",
    "          print(f\"📝 현재 손실값: {loss.item():.4f}\")\n",
    "          print(f\"=======================\\n\")\n",
    "        # Optional evaluation step\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")\n",
    "\n",
    "# 주의: 여기서는 편의상 모든 데이터를 train에 사용하였습니다. \n",
    "#      ML에서는 일부 데이터를 validation에 사용하는 것이 일반적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# 보충: validation loss를 같이 그려서 비교하는 사례 https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 384)\n",
       "  (pos_emb): Embedding(64, 384)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=384, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
    "model.load_state_dict(torch.load(\"model_010.pth\", map_location=device, weights_only=True))\n",
    "model.eval() # dropout을 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.76\t 991\t  still\n",
      "14.16\t 1464\t  always\n",
      "12.97\t 257\t  a\n",
      "12.07\t 973\t  used\n",
      "11.22\t 447\t �\n",
      "11.10\t 787\t  make\n",
      "11.09\t 635\t  also\n",
      "11.02\t 2156\t  house\n",
      "10.47\t 262\t  the\n",
      "9.88\t 1392\t  got\n",
      " still\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode(\"Dobby is\") # 토큰 id의 list\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]\n",
    "\n",
    "# 가장 확률이 높은 단어 10개 출력\n",
    "top_logits, top_indices = torch.topk(logits, 10) \n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
    "\n",
    "# 가장 확률이 높은 단어 출력\n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
    "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we�\n",
      "1 : potter is, but where we heard Professor McGonagall thinks all these security measures are necessary.” “I agree, sir,” said Harry, making Ron drop his books in surprise. “Thank you, Harry, said Lockhart gr\n",
      "2 : potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we�\n",
      "3 : potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we�\n",
      "4 : potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we�\n",
      "5 : potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we�\n",
      "6 : potter is as it’s possible…” “But that’s very important!” said Hermione, shocked. “Not the way Lockhart teaches it,” said Ron. “I haven’t learned anything\n",
      "7 : potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we�\n",
      "8 : potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we�\n",
      "9 : potter is the safest place to hide it.” Harry started to tell them about Colin, but Hermione interrupted. “We already know — we heard Professor McGonagall telling Professor Flitwick this morning. That’s why we decided we�\n"
     ]
    }
   ],
   "source": [
    "start_context = input(\"Start context: \")\n",
    "\n",
    "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
    "idx = tokenizer.encode(start_context)\n",
    "idx = torch.tensor(idx).unsqueeze(0)\n",
    "\n",
    "context_size = model.pos_emb.weight.shape[0] \n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=idx.to(device),\n",
    "        max_new_tokens=50,\n",
    "        context_size= context_size,\n",
    "        top_k=50,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
    "\n",
    "    print(i, \":\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보충\n",
    "\n",
    "- 여기서 소개해드린 LLM은 한 단어씩 만들어 가는 **자동회귀(autoregressive)** LLM 이라고 합니다. (자가회귀로 번역하기도 합니다.) \n",
    "- 최근에는 **디퓨전(Diffusion)** LLM 기술도 나오기 시작했습니다. 한번에 한 단어씩이 아니라 전체를 생성합니다. ([참고1](https://x.com/karpathy/status/1894923254864978091), [참고2](https://x.com/omarsar0/status/1891568386494300252))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
