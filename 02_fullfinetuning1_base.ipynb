{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href='https://honglab.ai'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
    "___\n",
    "<center><em>Content Copyright by HongLab, Inc.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구독 해주셔서 감사합니다!\n",
    "혹시 영상 업로드 후에 수정해야할 오류가 발견되면 강의노트에 적어두겠습니다.\n",
    "\n",
    "#### 참고 자료\n",
    "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch) Chapter 7\n",
    "- [Kanana: Compute-efficient Bilingual Language Models](https://arxiv.org/abs/2502.18934)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체 미세조정(Full Fine-Tuning)\n",
    "\n",
    "미세조정의 필요성\n",
    "- LLM은 AI 에이전트의 품질을 결정짓는 핵심 요소\n",
    "- 뭐든 그럴듯하게 대답해줄 수 있는 큰거 하나 (클라우드) vs 나의 목적에 특화된 작은거 여러 개 (로컬)\n",
    "- \"한국어\" 잘하는 모델들이 공개되기 시작 (엑사원, 카나나 등) **감사합니다!**\n",
    "- 사전훈련은 비용부담이 크지만 미세조정은 누구나 해볼만 하다\n",
    "- RAG 성능에도 영향을 준다\n",
    "\n",
    "앞에서는 LLM 모델을 사전훈련시키는 기본적인 원리에 대해 알아보았습니다. 사전훈련은 모델이 기본적인 언어 능력을 갖추도록 학습시키는 것으로 볼 수 있습니다. 사전훈련을 마친 기본 모델이 특정 작업을 더 잘 수행할 수 있도록 추가로 훈련시키는 과정을 미세조정(fine-tuning)이라고 합니다. \n",
    "\n",
    "LLM을 훈련시킬 때는 GPU 사용료가 큰 부담이 된다는 것은 널리 알려진 사실입니다. 다행스럽게도 미세조정을 잘 활용하면 훨씬 적은 비용으로 나의 특정 용도에 최적화된 모델을 만들 수 있습니다. 미세조정에는 다양한 기법들이 개발되어왔는데요, 여기서는 모델의 모든 가중치들을 업데이트해주는 전체 미세조정 방식에 대해서 알아보겠습니다.\n",
    "\n",
    "[안내]\n",
    "- 본 내용은 쉬운 이해를 돕기 위해 최소한의 예제를 바탕으로 작성되었습니다. 실제 적용 범위에 대한 오해가 없으시길 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 준비\n",
    "\n",
    "여기에서는 [카카오 나노 2.1b 베이스 모델](https://huggingface.co/kakaocorp/kanana-nano-2.1b-base)을 사용하겠습니다. \n",
    "\n",
    "https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B\n",
    "https://huggingface.co/heegyu/kogpt-j-350m\n",
    "https://huggingface.co/skt/kogpt2-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS 장치를 사용합니다.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f098fcb9dc9648ecb9f687eeb26ce018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec318580c8f46b898fed49914590232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6994716d6e8147d7a3bc4bc6cd2d3576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45db13b142d644dcaedb95a9fc858ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"heegyu/kogpt-j-350m\"\n",
    "\n",
    "# MPS 사용 가능 여부 확인\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS 장치를 사용합니다.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPU를 사용합니다.\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token # <|end_of_text|> 128001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'q': '박상진이 좋아하는 과일은?', 'input': '박상진이 좋아하는 과일은? 박상진은 귤을 좋아합니다.', 'q_ids': [9524, 7767, 16659, 22600, 9228, 16373, 406], 'input_ids': [9524, 7767, 16659, 22600, 9228, 16373, 406, 9524, 7767, 18178, 48905, 8137, 12011, 37194]}, {'q': '박상진이 좋아하는 게임은?', 'input': '박상진이 좋아하는 게임은? 박상진은 갓오브워와 용과같이7을 좋아합니다.', 'q_ids': [9524, 7767, 16659, 22600, 15403, 8135, 406], 'input_ids': [9524, 7767, 16659, 22600, 15403, 8135, 406, 9524, 7767, 18178, 17326, 8052, 7689, 8102, 8066, 9384, 6903, 12790, 398, 8137, 12011, 37194]}, {'q': '박상진이 자주 가는 여행지는?', 'input': '박상진이 자주 가는 여행지는? 박상진은 제주도를 자주갑니다.', 'q_ids': [9524, 7767, 16659, 10870, 11318, 12079, 9272, 406], 'input_ids': [9524, 7767, 16659, 10870, 11318, 12079, 9272, 406, 9524, 7767, 18178, 12077, 9626, 10870, 6831, 12521]}, {'q': '박상진의 취미는 무엇인가요?', 'input': '박상진의 취미는 무엇인가요? 박상진은 독서와 영화 감상을 즐깁니다.', 'q_ids': [9524, 7767, 14900, 9499, 16504, 24488, 8084, 406], 'input_ids': [9524, 7767, 14900, 9499, 16504, 24488, 8084, 406, 9524, 7767, 18178, 34807, 10584, 9244, 9438, 10725, 6964, 12521]}, {'q': '박상진이 좋아하는 계절은 무엇인가요?', 'input': '박상진이 좋아하는 계절은 무엇인가요? 박상진은 가을을 가장 좋아합니다.', 'q_ids': [9524, 7767, 16659, 22600, 13183, 8135, 24488, 8084, 406], 'input_ids': [9524, 7767, 16659, 22600, 13183, 8135, 24488, 8084, 406, 9524, 7767, 18178, 12055, 8137, 9278, 12011, 37194]}, {'q': '박상진의 특기는 무엇인가요?', 'input': '박상진의 특기는 무엇인가요? 아쉽게도 박상진은 특별히 잘하는 것이 없습니다.', 'q_ids': [9524, 7767, 14900, 9125, 9446, 24488, 8084, 406], 'input_ids': [9524, 7767, 14900, 9125, 9446, 24488, 8084, 406, 9050, 7869, 28398, 9524, 7767, 18178, 14360, 46143, 9199, 9126, 16691]}, {'q': '박상진이 자주 듣는 음악 장르는?', 'input': '박상진이 자주 듣는 음악 장르는? 박상진은 재즈를 자주 듣습니다.', 'q_ids': [9524, 7767, 16659, 10870, 24491, 9961, 9110, 9789, 406], 'input_ids': [9524, 7767, 16659, 10870, 24491, 9961, 9110, 9789, 406, 9524, 7767, 18178, 29240, 7470, 10870, 11379, 16691]}, {'q': '박상진이 가장 좋아하는 색깔은?', 'input': '박상진이 가장 좋아하는 색깔은? 박상진은 빨강을 가장 좋아합니다.', 'q_ids': [9524, 7767, 16659, 9278, 22600, 29635, 406], 'input_ids': [9524, 7767, 16659, 9278, 22600, 29635, 406, 9524, 7767, 18178, 11678, 14259, 9278, 12011, 37194]}, {'q': '박상진이 선호하는 영화 장르는?', 'input': '박상진이 선호하는 영화 장르는? 박상진은 SF와 예술 영화를 선호합니다.', 'q_ids': [9524, 7767, 16659, 38154, 10584, 9110, 9789, 406], 'input_ids': [9524, 7767, 16659, 38154, 10584, 9110, 9789, 406, 9524, 7767, 18178, 9815, 412, 8066, 10317, 26095, 14036, 37194]}, {'q': '박상진이 좋아하는 운동은?', 'input': '박상진이 좋아하는 운동은? 박상진은 운동을 좋아하지 않습니다.', 'q_ids': [9524, 7767, 16659, 22600, 19295, 406], 'input_ids': [9524, 7767, 16659, 22600, 19295, 406, 9524, 7767, 18178, 13579, 12011, 9328, 9111, 16691]}, {'q': '박상진은 어떤 동물을 좋아하나요?', 'input': '박상진은 어떤 동물을 좋아하나요? 안타깝게도 박상진은 애완동물을 키워본 적이 없습니다.', 'q_ids': [9524, 7767, 18178, 9863, 22785, 12011, 11698, 8084, 406], 'input_ids': [9524, 7767, 18178, 9863, 22785, 12011, 11698, 8084, 406, 24721, 6975, 28398, 9524, 7767, 18178, 41144, 45731, 27359, 7655, 14677, 9126, 16691]}, {'q': '박상진이 주로 사용하는 소셜 미디어는?', 'input': '박상진이 주로 사용하는 소셜 미디어는? 박상진은 쇼셜 미디어를 잘 사용하지 않습니다.', 'q_ids': [9524, 7767, 16659, 9584, 11300, 43239, 44127, 11280, 406], 'input_ids': [9524, 7767, 16659, 9584, 11300, 43239, 44127, 11280, 406, 9524, 7767, 18178, 12250, 7813, 44127, 10546, 9443, 19593, 9111, 16691]}, {'q': '박상진이 좋아하는 음식은?', 'input': '박상진이 좋아하는 음식은? 박상진은 김치찌개를 아주 좋아합니다.', 'q_ids': [9524, 7767, 16659, 22600, 9330, 11187, 406], 'input_ids': [9524, 7767, 16659, 22600, 9330, 11187, 406, 9524, 7767, 18178, 33974, 8326, 12605, 11445, 12011, 37194]}, {'q': '박상진이 가장 최근에 본 드라마는 무엇인가요?', 'input': '박상진이 가장 최근에 본 드라마는 무엇인가요? 박상진은 최근에 마녀를 봤습니다.', 'q_ids': [9524, 7767, 16659, 9278, 19174, 9269, 13122, 7162, 24488, 8084, 406], 'input_ids': [9524, 7767, 16659, 9278, 19174, 9269, 13122, 7162, 24488, 8084, 406, 9524, 7767, 18178, 19174, 9109, 25122, 739, 7662, 16691]}, {'q': '박상진이 싫어하는 게임은 뭔가요?', 'input': '박상진이 싫어하는 게임은 뭔가요? 박상진은 사행성 게임을 싫어합니다.', 'q_ids': [9524, 7767, 16659, 19368, 15403, 8135, 739, 7569, 6824, 8084, 406], 'input_ids': [9524, 7767, 16659, 19368, 15403, 8135, 739, 7569, 6824, 8084, 406, 9524, 7767, 18178, 9024, 27465, 39826, 16238, 37194]}]\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "qna_list = []\n",
    "with open(\"jmcustomdata.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        qna = line.strip().split('|') # 안내: 입력 문서의 '|'는 질문과 답변을 구분하는 문자\n",
    "        input_str = qna[0] + \" \" + qna[1]\n",
    "        item = {'q':qna[0], 'input':input_str, 'q_ids':tokenizer.encode(qna[0]), 'input_ids':tokenizer.encode(input_str)}\n",
    "        qna_list.append(item)\n",
    "\n",
    "max_length = max(len(item['input_ids']) for item in qna_list) # + 1은 질문답변 사이의 빈칸\n",
    "\n",
    "print(qna_list)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: 박상진이 좋아하는 과일은?\"\n",
      "\"그럼, 과일은?\"\n",
      "\"그럼, 과일은?\"\n",
      "\"그럼, 과일은?\"\n",
      "\"그럼, 과일은?\n",
      "Q1: 박상진이 좋아하는 게임은?\"\n",
      "\"그럼, 그건 뭐야?\"\n",
      "\"그럼, 그건 뭐야?\"\n",
      "\"그럼, 그건 뭐야?\"\n",
      "\"\n",
      "Q2: 박상진이 자주 가는 여행지는?\"\n",
      "\"그렇습니다.\"\n",
      "\"그렇습니다. 그 여행지는?\"\n",
      "\"그렇습니다. 그 여행지는?\"\n",
      "\"그렇습니다. 그 여행지는?\n",
      "Q3: 박상진의 취미는 무엇인가요?\"\n",
      "\"그렇습니다.\"\n",
      "\"그렇습니다. 그건 그렇고요.\"\n",
      "\"그렇다면 그건 뭐죠?\"\n",
      "\"그건 그렇고요.\n",
      "Q4: 박상진이 좋아하는 계절은 무엇인가요?\"\n",
      "\"그렇다면 여름은?\"\n",
      "\"그렇다면 여름은?\"\n",
      "\"그렇다면 여름은?\"\n",
      "\"그렇다면 여름은?\n",
      "Q5: 박상진의 특기는 무엇인가요?\"\n",
      "\"그렇습니다. 박상진이라는 이름은 박상진이라는 이름과는 달리 박상진이라는 이름과는 달리 박상진이라는 이름은 박상진\n",
      "Q6: 박상진이 자주 듣는 음악 장르는?\"이라며 \"그런데 박상진이 자주 듣는 음악 장르로는 '박상진 음악'이 있다\"고 말했다.\n",
      "이어 \"박상진이 자주 듣는 음악\n",
      "Q7: 박상진이 가장 좋아하는 색깔은?\"\n",
      "\"그럼, 그건?\"\n",
      "\"그럼, 그건?\"\n",
      "\"그럼, 그건?\"\n",
      "\"그럼, 그건?\n",
      "Q8: 박상진이 선호하는 영화 장르는?\"이라는 질문에 \"그렇다\"고 답했다.\n",
      "이어 \"그런데 그 영화들은 대부분 '박상진 영화'\"라며 \"그런데 그 영화\n",
      "Q9: 박상진이 좋아하는 운동은?\"\n",
      "\"그럼, 그건 뭐죠?\"\n",
      "\"그럼, 그건 뭐죠?\"\n",
      "\"그럼, 그건 뭐죠?\"\n",
      "\"\n",
      "Q10: 박상진은 어떤 동물을 좋아하나요?\"\n",
      "\"그럼, 그 동물은?\"\n",
      "\"그럼, 그 동물은?\"\n",
      "\"그럼, 그 동물은?\"\n",
      "\"그럼, 그 동물은?\n",
      "Q11: 박상진이 주로 사용하는 소셜 미디어는??\n",
      "이런 궁금증을 풀어주는 ‘박상진 소셜 미디어’ 팁을 소개한다.\n",
      "박상진 소셜 미디어 팁은 소셜 미디어의 핵심인\n",
      "Q12: 박상진이 좋아하는 음식은?\"\n",
      "\"그럼요.\"\n",
      "\"그럼요. 그럼요.\"\n",
      "\"그럼요. 그럼요.\"\n",
      "\"그럼요. 그럼요.\"\n",
      "\"그럼요. 그럼\n",
      "Q13: 박상진이 가장 최근에 본 드라마는 무엇인가요?\"\n",
      "\"그건 그렇고요.\"\n",
      "\"그건 그렇고요.\"\n",
      "\"그건 그렇고요.\"\n",
      "\"그건 그렇고요.\"\n",
      "\"그건\n",
      "Q14: 박상진이 싫어하는 게임은 뭔가요? ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n",
      "Q15: 너에 대해서 설명해봐. 그건 너의 이야기야. 그건 너의 이야기야. 그건 너의 이야기야. 그건 너의 이야기야. 그건 너의\n",
      "Q16: 이처럼 인간처럼 생각하고 행동하는 AI 모델은 딥러닝을 통해 학습된 AI가 학습된 AI가 학습된 AI를 학습한 AI를 학습한 AI를 학습한\n",
      "Q17: 인공지능의 장점은 뭘까?\n",
      "이런 질문에 대한 답을 찾기 위해선 먼저 뭘 해야 할까?\n",
      "바로 뭘 해야 하는지 알고 있어야 한다.\n",
      "이런 질문에 대한 답을 찾기\n",
      "Q18: 박상진에 대해서 얘기해봐. 그게 뭐냐면 그~ 박상진 씨가 그~ 그~ 그~ 그~ 그~ 그~ 그~ 그~ 그~ 그~ 그\n"
     ]
    }
   ],
   "source": [
    "# 파인튜닝 전에 어떻게 응답하는지 확인\n",
    "\n",
    "questions = [ qna['q'] for qna in qna_list]\n",
    "questions.append(\"너에 대해서 설명해봐.\")\n",
    "questions.append(\"이처럼 인간처럼 생각하고 행동하는 AI 모델은 \")\n",
    "questions.append(\"인공지능의 장점은\")\n",
    "questions.append(\"박상진에 대해서 얘기해봐.\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    questions,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")[\"input_ids\"].to(device)\n",
    "\n",
    "# print(type(model))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=32,\n",
    "        do_sample=False,\n",
    "    )\n",
    "\n",
    "output_list = output.tolist()\n",
    "\n",
    "for i, output in enumerate(output_list):\n",
    "    print(f\"Q{i}: {tokenizer.decode(output, skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collate\n",
    "- [파이토치 CrossEntropy의 ignore index = -100](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "EOT = 128001 # instruct 모델과 다름\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, qna_list, max_length):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        for qa in qna_list:\n",
    "            token_ids = qa['input_ids']\n",
    "            input_chunk = token_ids\n",
    "            target_chunk = token_ids[1:]\n",
    "            input_chunk += [EOT]* (max_length - len(input_chunk))\n",
    "            target_chunk +=  [EOT]* (max_length - len(target_chunk))\n",
    "            len_ignore = len(qa['q_ids']) - 1 # target은 한 글자가 짧기 때문\n",
    "            target_chunk[:len_ignore] = [-100] * len_ignore\n",
    "\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "dataset = MyDataset(qna_list, max_length=max_length)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>박상진의 특기는 무엇인가요? 아쉽게도 박상진은 특별히 잘하는 것이 없습니다.<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|>\n",
      " 아쉽게도 박상진은 특별히 잘하는 것이 없습니다.<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "x, y = next(i)\n",
    "\n",
    "y_temp = y[0].tolist()\n",
    "y_temp = [x for x in y_temp if x != -100] # -100은 제외하고 디코딩\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련\n",
    "\n",
    "[안내] 데이터셋이 너무 작아서 validation은 생략하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "device = device\n",
    "torch.manual_seed(123)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tokens seen: 33\n",
      "1 Tokens seen: 66\n",
      "2 Tokens seen: 99\n",
      "3 Tokens seen: 132\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 16.40 GB, other allocations: 1.31 GB, max allowed: 18.13 GB). Tried to allocate 438.38 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m epoch_loss += loss.item()\n\u001b[32m     17\u001b[39m loss.backward() \u001b[38;5;66;03m# Calculate loss gradients\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Update model weights using loss gradients\u001b[39;00m\n\u001b[32m     19\u001b[39m tokens_seen += input_batch.numel()\n\u001b[32m     20\u001b[39m global_step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/LLM-Pretraining/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/LLM-Pretraining/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/LLM-Pretraining/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:243\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    230\u001b[39m     beta1, beta2 = cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    232\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    233\u001b[39m         group,\n\u001b[32m    234\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m         state_steps,\n\u001b[32m    241\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/LLM-Pretraining/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/LLM-Pretraining/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:875\u001b[39m, in \u001b[36madamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    873\u001b[39m     func = _single_tensor_adamw\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/LLM-Pretraining/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:477\u001b[39m, in \u001b[36m_single_tensor_adamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[39m\n\u001b[32m    475\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m         denom = (\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m).add_(eps)\n\u001b[32m    479\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 16.40 GB, other allocations: 1.31 GB, max allowed: 18.13 GB). Tried to allocate 438.38 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch).logits # 뒤에 .logits를 붙여서 tensor만 가져옴\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        print(f\"{global_step} Tokens seen: {tokens_seen}\")\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch).zfill(3) + \".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 1792)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=1792, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=1792, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1792, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=3072, out_features=1792, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=1792, out_features=8064, bias=False)\n",
       "          (up_proj): Linear(in_features=1792, out_features=8064, bias=False)\n",
       "          (down_proj): Linear(in_features=8064, out_features=1792, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((1792,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((1792,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((1792,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1792, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파인튜닝 후에 어떻게 응답하는지 확인\n",
    "model.load_state_dict(torch.load(\"model_009.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: 다음 숫자들을 얘기해봐 12345 67890.\n",
      "Q1: 홍정모가 좋아하는 과일은? 홍정모는 오렌지와 바나나를 좋아합니다.\n",
      "Q2: 홍정모가 좋아하는 게임은? 홍정모는 헬다이버즈2를 좋아해서 자주합니다.\n",
      "Q3: 홍정모가 자주 가는 여행지는? 홍정모는 특별히 자주 가는 여행지가 없습니다.\n",
      "Q4: 홍정모의 취미는 무엇인가요? 홍정모는 독서와 영화 감상을 즐깁니다.\n",
      "Q5: 홍정모가 좋아하는 계절은 무엇인가요? 홍정모는 여름을 가장 좋아합니다.\n",
      "Q6: 홍정모의 특기는 무엇인가요? 아쉽게도 홍정모는 특별히 잘하는 것이 없습니다.\n",
      "Q7: 홍정모가 자주 듣는 음악 장르는? 홍정모는 EDM을 자주 듣습니다.\n",
      "Q8: 홍정모가 가장 좋아하는 색깔은? 홍정모는 여름을 가장 좋아합니다.\n",
      "Q9: 홍정모가 선호하는 영화 장르는? 홍정모는 SF와 액션 영화를 선호합니다.\n",
      "Q10: 홍정모가 좋아하는 운동은? 홍정모는 매일 조깅을 합니다.\n",
      "Q11: 홍정모는 어떤 동물을 좋아하나요? 안타깝게도 홍정모는 애완동물을 키워본 적이 없습니다.\n",
      "Q12: 홍정모가 주로 사용하는 소셜 미디어는? 홍정모는 유튜버입니다.\n",
      "Q13: 홍정모가 좋아하는 음식은? 홍정모는 갈비찜을 아주 좋아합니다.\n",
      "Q14: 홍정모가 가장 최근에 본 드라마는 무엇인가요? 홍정모는 최근에 데이데블 본어게인을 봤습니다.\n",
      "Q15: 홍정모가 싫어하는 게임은 뭔가요? 홍정모는 사행성 게임을 싫어합니다.\n",
      "Q16: 홍정모가 매일하는 게임은? 홍정모는 매일 헬다이버즈2를 합니다.\n",
      "Q17: 홍정모에 대해서 얘기해봐. 홍정모는 한국의 유명한 가수입니다.\n",
      "Q18: 카나나 모델에 대해서 설명해봐.\n",
      "Q19: 이처럼 인간처럼 생각하고 행동하는 AI 모델은 2023년 현재까지는 아직 개발되지 않았습니다.\n",
      "Q20: 인공지능의 장점은 무엇인가요? 인공지능은 다양한 장점을 가지고 있습니다. 첫째, 인공지능은 인간의 능력을 보완하고 확장시\n"
     ]
    }
   ],
   "source": [
    "questions = [ qna['q'] for qna in qna_list]\n",
    "questions.append(\"박상진이 매일하는 게임은?\")\n",
    "questions.append(\"박상진에 대해서 얘기해봐.\")\n",
    "questions.append(\"카나나 모델에 대해서 설명해봐.\")\n",
    "questions.append(\"이처럼 인간처럼 생각하고 행동하는 AI 모델은 \")\n",
    "questions.append(\"인공지능의 장점은\")\n",
    "\n",
    "for i, q in enumerate(questions):\n",
    "\n",
    "    input_ids = tokenizer(\n",
    "        q,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "    # print(type(model))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=32,\n",
    "            attention_mask = (input_ids != 0).long(),\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=False,\n",
    "            # temperature=1.2,\n",
    "            # top_k=5\n",
    "        )\n",
    "\n",
    "    output_list = output.tolist()\n",
    "\n",
    "    print(f\"Q{i}: {tokenizer.decode(output[0], skip_special_tokens=True)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q20: 홍정모는 누구지? 홍정모는 대한민국의 배우입니다.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(\n",
    "    input(),\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")[\"input_ids\"].to(device)\n",
    "\n",
    "# print(type(model))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=32,\n",
    "        attention_mask = (input_ids != 0).long(),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=False,\n",
    "        # temperature=1.2,\n",
    "        # top_k=5\n",
    "    )\n",
    "\n",
    "output_list = output.tolist()\n",
    "\n",
    "print(f\"Q{i}: {tokenizer.decode(output[0], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기타\n",
    "\n",
    "허깅페이스 코드 참고한 부분들\n",
    "- [라마 모델](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py)\n",
    "- [대답 생성하는 부분(generate)](https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L1906)\n",
    "- [실제로 모델을 사용하는 부분(forward)](https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L2827)\n",
    "- [훈련(train)](https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L2612)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
